[
  {
    "path": "posts/2025-04-02-age-in-mizer/",
    "title": "Age in mizer",
    "description": "In this blog post, we introduce an extension that allows you to calculate\ndynamic growth curves and ages at size in mizer. This addition will improve how\nmizer is calibrated to data and also allows it to be interpreted and compared \nto age-based models, potentially increasing the utility of mizer in the \nassessment and advice process.",
    "author": [
      {
        "name": "Luke Broadbent",
        "url": {}
      },
      {
        "name": "Michael A. Spence",
        "url": {}
      }
    ],
    "date": "2025-04-02",
    "categories": [],
    "contents": "\n\nContents\nIntroduction\nCalculating age in mizer\nNumbers at age\nMortality rates\n\nSensitivity to no_w and dt\nDiscussion\nReferences\n\nIntroduction\nThe majority of assessment models for category 1 stocks in the International Council for Exploration of the Seas (ICES) are age based. This is a natural way of thinking about population dynamics as in a closed system, the number of individuals in a cohort, \\(N\\), can only go down as they die. The dynamics of a cohort are\n\\[\\begin{equation}\n    \\frac{dN}{dt}=-ZN\n    \\tag{1}\n\\end{equation}\\]\nwhere \\(Z=F+M\\), with \\(F\\) being the fishing mortality and \\(M\\) being the natural mortality. Fishing mortality and natural mortality can vary in time.\nFor an age-based model this has the solution that the numbers at time \\(t\\) in age-class \\(a\\) is\n\\[\\begin{equation}\n    N_{a,t}=N_{a-1,t-1}\\exp(-Z_{a-1,t})\n    \\tag{2}\n\\end{equation}\\]\nfor \\(a=2,\\ldots{},A-1\\) and \\(t=1,\\ldots\\). For the first age-class, the number in the new cohort is the recruits\n\\[\\begin{equation}\n    N_{1,t}=R_{t}\\exp(-Z_{0,t})\n    \\tag{3}\n\\end{equation}\\]\nfor all \\(t\\). Often \\(Z_{0,t}\\) is zero if there are no catches of age-class one in the data.\nThe final age class, \\(A\\), is a plus group, which means there is no maximum age of a fish,\n\\[\\begin{equation}\n    N_{A,t}=N_{A-1,t-1}\\exp(-Z_{A-1,t}) + N_{A,t-1}\\exp(-Z_{A,t}),\n    \\tag{4}\n\\end{equation}\\]\nwith \\(Z_{a,t}=M_{a,t}+F_{a,t}\\) for \\(a=0,\\ldots{},A\\) and all times.\nNote that these are age classes that have the interval one year and not the ages of the fish. Some stocks have the first age class being age 0 (e.g. North Sea whiting), where as other have the first age class being older (e.g. age 3 for North Sea saithe).\nMost category 1 assessments are based on equations (2)–(4), with additional features (e.g., process error in Nielsen and Berg 2014). The same equations are commonly the basis to give catch advice, calculate reference points (e.g. MSY) and perform management strategy evaluations (MSE).\nA lot of data studies are specifically designed to collect data for age-based models. For example, fish that are aged on surveys using a length-stratified design.\nThis design is good for finding the age at length, so that fish can be aged just by knowing their length and numbers at age can be calculated. However, the design is not as good at finding length from age, which means that growth curves can be difficult to calculate.\nThere are also many multispecies models that are age-based (Trijoulet et al. 2019; Trijoulet, Fay, and Miller 2020; Lewy and Vinther 2004). In some cases, emergent natural mortality from age-based multispecies models are used as inputs to single-species assessments (e.g., ICES 2024).\nDespite strong arguments for adopting size-based models over age-based models (Andersen 2019) , we are unaware of any data-rich assessments that use size-based models. This work was motivated by the aim to use the multispecies size spectrum model, mizer (Hartvig, Andersen, and Beyer 2011; Blanchard et al. 2014; Scott, Blanchard, and Andersen 2014) as an age-based model to fit with current assessment and MSE frameworks. This will take advantage of the mechanistic dynamics of the mizer model, while keeping to the age-structured frameworks used in ICES.\nIn this blog we will explain and demonstrate how we calculate emergent age in mizer.\nCalculating age in mizer\nGrowth is an emergent property of feeding (Andersen 2019) and so is\nsize-at-age. To calculate the emergent size at age in mizer at time\n\\(t_0\\), we introduce an immortal individual (II) of species \\(i\\) and\ntrack the size of that individual. At time \\(t\\), the size of the II will\nbe \\(I_i(t_0,t)\\), with\n\\[\\begin{equation}\n\\frac{\\partial I_i}{\\partial t} \\;=\\; g_i\\bigl(I_i(t_0,t),t\\bigr).\n\\tag{5}\n\\end{equation}\\]\nSolving this from \\(t_0\\) to time \\(T\\) with boundary condition\n\\(I_i(t_0, t_0) = w_{0,i}\\), we know that an individual of species \\(i\\) and\nage \\(T - t_0\\) will be size \\(I_i(t_0, T)\\). In mizer, fish cannot overtake\neach other in size, therefore we know that fish smaller than \\(I_i(T)\\) will be\nyounger, and larger fish will be older. If we introduce such IIs at\nannual increments, then we can follow different age classes throughout\nthe model. Figure 1 demonstrates the process, showing how, for a given species, age is calculated.\n\n\n\nFigure 1: Demonstration of how we calculate weights for immortal individuals across time. Each line represents the weight of one II, each introduced annually.\n\n\n\nWe solve equation (5) in mizer for time dt numerically given weight classes w, with differences dw. If at the current time the II is size cur_waa then it will be in size class\n\n\ncur_idx <- max(which(cur_waa >= params@w))\n\n\nand will grow at rate\n\n\ng <- grow[cur_idx]\ntime_to_end <- (togro - cur_waa) / g # how far is next size class, can i grow it in dt?\n\n\nIt will grow at this rate until it reaches the next size class\n\n\ntogro <- params@w[cur_idx + 1]\n\n\nwhich will take time\n\n\ntime_to_end <- (togro - cur_waa) / g\n\n\nInitially the II will grow for time dt but will move through weight classes. We monitor how long is left to grow with variable time_left intially setting it to dt. If time_to_end<=time_left then the II’s weight will be\n\n\ncur_waa <- cur_waa + g * time_left\n\n\notherwise it will grow to the next size class for time_to_end and we update the time remaining\n\n\ncur_waa <- cur_waa + g * time_to_end\ntime_left <- time_left - time_to_end \n\n\nThe process is repeated until time_to_end<=time_left.\nFigure 2 shows the emergent weight at age for whiting in mizer.\n\n\n\nFigure 2: Emergent growth curve for whiting.\n\n\n\nWe added the above to the project and project_simple functions so that it updates the size of the IIs each dt. In addition we added a new slot to the MizerSim objects so that we can store the weight at age for all ages, time steps and species, waa.\n\n\n#the mizerSim object - now with a waa section\nsetClass( \n    \"MizerSim\",\n    slots = c(\n        params = \"MizerParams\",\n        n = \"array\",\n        effort = \"array\",\n        n_pp = \"array\",\n        n_other = \"array\",\n        waa = \"array\"\n    )\n)\n\n\nEach year we add a new II, and also remove the oldest II at the same time. We give an argument to project to input the initial weights at age (waa_initial), a matrix with dimensions number of species and maximum age (defaulted to 20), nages. If absent the initial weights at age are calculated from the getGrowthCurves function.\nThe project function will now return a mizerSim object with a waa slot which contains an array with the dimensions t_max*t_save, number of species and nages.\nWe demonstrate the weight at age using the North Sea model with fishing mortality from stock assessments (historicfishingM see Spence et al. (2024)) from 1984 to 2019. We ran the model to the steady state by running it for 100 years using 1984 fishing and then projected it to 2019.\n\n\n#project to steady state - so that we can use the waa generated here as initial_waa\n#fishing array is the historicfishingM remade for mizer\ntosteady <- project(params, effort = fishing_array[1,],t_max =100, initial_n = params@initial_n)\n\n#projecting, using the values from the end of the steady state run for n, npp and waa\nprojection <- project(params, effort = fishing_array,  initial_n = (tosteady@n)[(dim(tosteady@n)[1]),,],\n                      initial_n_pp = (tosteady@n_pp)[(dim(tosteady@n)[1]),],\n                      waa_initial = tosteady@waa[1001,,]) \n\n\n\n\n\nFigure 3: The black line shows the weight at age inputs to SMS’ key-run (ICES 2024) (and the stock assessent) for whiting and the red line shows the mizer estimate of weight at age for whiting using NS_params\n\n\n\nIn Figure 3 we show the size at age of whiting and compare it to weight at age inputs to SMS’ key-run (ICES 2024). Using the default mizer model NS_params we show that the weight at age of whiting changes over the simulation, with a similar pattern to the inputs to SMS, however, the scale and range are different.\nNumbers at age\nGiven the IIs we can calculate the numbers at age. Suppose that at time \\(t\\) the density of numbers at weight is shown below, with IIs aged one, \\(I_i(t-1,t)=0.2\\), and two, \\(I_i(t-2,t)=5\\), being shown.\n\n\n\nThe numbers younger than age one are all of the individuals smaller than \\(I_i(t-1,t)=0.2\\), which in the figure above is 14671.88. The number of individuals younger than two years old are smaller than \\(I_i(t-2,t)=5\\), which in the figure is 17671.88. Therefore, 14671.88 are in the youngest age class (less than one years old) and 3000 individuals are in the age class between one and two years old.\nIn this example the IIs were on the boundary of the weight-classes. However, in practice this will almost surely not happen. The IIs will fall between weight-classes, and so, to assign an age to individuals in that weight-class we describe how individuals are distributed within the weight class. The plot below is more likely:\n\n\n\nIt is clear that the individuals in the red bars are less than one, and the individuals in the blue bar are less than two but older than one, but it is not clear how old the individuals in the white bars are.\nDefining how the individuals in the white bars are distributed is down to the user. In this work we defined it as following a power law. Specifically the density of individuals between sizes \\(w_0\\) and \\(w_1\\) was\n\\[\\begin{equation}\n\\alpha{}w^{\\beta}.\n\\end{equation}\\]\nWe set\n\\[\\begin{equation}\n\\beta=\\frac{\\log(n(w_1))-\\log(n(w_0))}{\\log(w_1)-\\log(w_0)},\n\\end{equation}\\]\nand\n\\[\\begin{equation}\n\\alpha=\\frac{n(w_0)(w_1-w_0)(\\beta+1)}{w_1^{\\beta+1}-w_0^{\\beta+1}},\n\\end{equation}\\]\nwhich ensures that the total number in the weight-class is constant in both cases.\nThe example above becomes:\n\n\n\n\n\n\nFigure 4: The top plot shows the evolution of individual whiting cohorts through time. The lower plots shows the fishing mortality over time for whiting from Spence et al. (2024)\n\n\n\nMortality rates\nBy calculating the numbers at age, as done in Section ??, we can calculate how many individuals die in a cohort in a year. Consider that at time \\(t-1\\) and \\(t\\) we have calculated numbers age \\(a-1\\) and \\(a\\) respectively, then we can rearrange equation (2) to find\n\\[\\begin{equation}\n    Z_{a-1,t-1}=-\\ln(N_{a,t})+\\ln(N_{a-1,t-1}).\n    \\tag{6}\n\\end{equation}\\]\nThis is the total mortality for age \\(a-1\\) at time \\(t-1\\). By calculating the numbers caught at age \\(a\\) in time \\(t-1\\), \\(C_{a-1,t-1}\\), in a similar way to how we calculate the numbers at age, we can calculate the fishing mortality\n\\[\\begin{equation}\n    F_{a-1,t-1}=\\frac{Z_{a-1,t-1}C_{a-1,t-1}}{N_{a-1,t-1}(1-\\exp(-Z_{a-1,t-1}))}\n    \\tag{7}\n\\end{equation}\\]\nand the natural mortality\n\\[\\begin{equation}\n    M_{a-1,t-1}=Z_{a-1,t-1}-F_{a-1,t-1}.\n    \\tag{8}\n\\end{equation}\\]\nAfter a simulation we get the numbers at age and the numbers caught at age\n\n\nnumbers <- get_num_by_year_by_age(sim)\ncatch <- get_catch_by_year_by_age(sim)\n\n\nThe get_catch_by_year_by_age function works the same as get_num_by_year_by_age, but prior to the numbers in size classes being summed over ages, they are multiplied by the size, species specific fishing mortality, acquired from getFMort. The catch here is the same as in mizer’s getYield.\nWe calculate equations (6) and (7) for the ith year, jth species and kth age class to get \\(Z_{i,k}\\) and \\(F_{i,k}\\)\n\nz <- -log(numbers[i+1,j,k+1]) + log(numbers[i,j,k])\nF_m <- catch[i-1,j,k]*z)/(numbers[i,j,k]-next_alive) ### F_m rather than F as F is protected\n\nand equation (8) to get \\(M_{i,k}\\)\n\n\nm <- z - F_m\n\n\nFigure 5 is the emergent \\(Z\\), \\(F\\) and \\(M\\) over time using the historical fishing mortality.\n\n\n\nFigure 5: Plots depict the \\(Z\\), \\(F\\) and \\(M\\) rates for whiting of different ages over time\n\n\n\nSensitivity to no_w and dt\nDue to the numerical integration of the partial differential equation (pde) in mizer, the II do not follow the distribution of fish density exactly and this sometimes results in negative \\(M\\). To investigate this we followed one individual and their growth for different values of dt and no_w. We initialised the params object for no_w equal to 100, 1000 and 10000\n\n\nparams <- newMultispeciesParams(NS_params@species_params, no_w = no_w)\nallgrow <- getEGrowth(params)\ngs <- allgrow[6,]\n\n\nand assumed a constant growth rate gs for a whiting individual. We initialised the population at zero except in the first size class where we set it so that there was only one individual.\n\n\nnum <- rep(0,length(params@w))\nnum[1] <- 1 / params@dw[1]\n\n\nAssuming no mortality and no recruitment we updated the numbers at size for 10 years using the numerical pde solver in mizer (see supplementary for the code) and compared the size distribution with the size of an II at the same age.\n\n\n\nFigure 6: Comparison of II size prediction to mizer’s numerical solution. The grid cell value is the proportion of individuals in the numerical solution that are smaller than the II. Each simulation has a different dt and no_w.\n\n\n\n\n\n\nFigure 7: The numerical solution of the growth with different dt and no_w. Each plot contains 3 lines, indicating a different value of dt - black is 0.1, blue is 0.01 and red is 0.001. Each row of plots indicates that the example’s no_w, increasing from top to bottom. The left columns shows age 1 and right age 4.\n\n\n\nWe compared the proportion of individuals that are smaller than the II and found that as dt got smaller and no_w got bigger the proportion approached 50%, Figure 6. Further, as dt got smaller and no_wgot bigger the range of sizes at age decreased Figure 7.\nTherefore for more accurate age-based information we are required to choose a finer resolution for the numerical solver in mizer. We demonstrate this on the North Sea model for values of dt equal to 0.1, 0.01 and 0.001, and no_w equal to 100, 1000 and 2000.\n\nTable 1: Proportion of Negative Ms in ages 1 to 6 for all species. The rows represent different dts and the columns different no_w. We did not run it for dt=0.001 and no_w=2000 as the file was too large.\n\n100\n1000\n2000\n0.1\n0.1015873\n0.0099206\n0.002381\n0.01\n0.0746032\n0.0000000\n0.000000\n0.001\n0.0726190\n0.0000000\nNA\n\nDecreasing dt and increasing no_w makes the numerial integration more accurate and stablises the results. This comes at a cost, as the MizerSim object gets very large.\nDiscussion\nMost models used in advice are age-based. In this blog post, we have introduced a way of calculating emergent age in mizer, potentially increasing the utility of mizer when it comes to giving management advice.\nFor example, mizer could be used as an operating model for MSEs. A common MSE framework is to use an operating model to test management actions. The operating model stands in for reality and management actions, such as harvest control rules, are run (Punt et al. 2016). This process involves the operating model generating data, which assessment models are fitted to. As data for assessment models is age resolved, the operating model has to be able to sample age resolved data. By introducing emergent age in mizer, mizer can now generate age-based data, meaning that it can be used as an operating model in the MSE frameworks.\nSome category 1 assessments, those that have full analytical assessments, use natural mortality at age from fitted multispecies models as inputs to the assessment. For example, many North Sea stocks use natural mortality estimates from the stochastic multispecies model (Lewy and Vinther 2004). Typically, assessment models require natural mortality at age rather than size. In Section ?? we showed that we can calculate emergent natural mortality at age. Therefore, coupled with dynamical fitting, (Spence et al. 2021), mizer could be used to provide natural mortality estimates as inputs to single-species assessments.\nMany data collection schemes are designed to be fit to age-based models, for example, length stratified sample is used on surveys to calculate age-length keys. For these reasons, it can be difficult to incorporate age-based data when calibrating mizer. Furthermore, the data collected are not in a steady state (e.g., see Figure 3). Using the ages process described here, we can compare these data with mizer. For example, growth could be tuned by looking at emergent growth rates rather than steady states.\nIn many cases, fishing mortality from stock assessments has been used to drive the dynamics of the mizer model (Blanchard et al. 2014; Spence, Blackwell, and Blanchard 2016; Spence et al. 2024). Typically fishing mortality from stock assessments is age-based. In previous studies, the fishing mortality inputs were some kind of average, for example Fbar, or some steady-state assumption about age (Spence et al. 2024). Using this approach, age-based fishing mortality can be implemented in age classes as they change size throughout the simulation as done in the assessment. However, how selectivity occurs within an age can be difficult to calculate (Spence et al. 2024), particularly at lower ages.\nThe work presented here is exact in the limit when dt and dw are 0, however practically this is not possible. We showed that as dt and dw get smaller the age estimation becomes more accurate, however, inaccuracies in the ageing process can lead to some strange behaviour. For example, we found that for the default values of dt and dw some cohorts natural mortality was less than 0, i.e. \\(M<0\\), which could cause difficulties when comparing mizer to age-based models. This could be caused by the numerical integration and/or how we say the lengths of fish within an age class are distributed. More research is required, although we suspect these problems occur due to how the emergent catch is calculated.\nIn this blog post, we introduced an extension that allows you to calculate dynamic growth curves and ages at size in mizer. This addition will improve how mizer is calibrated to data and also allows it to be interpreted and compared to age-based models, potentially increasing the utility of mizer in the assessment and advice process.\nReferences\n\n\n\nAndersen, Ken H. 2019. Fish Ecology, Evolution, and Exploitation: A New Theoretical Synthesis. Princeton University Press.\n\n\nBlanchard, Julia L., Ken H. Andersen, Finlay Scott, Niels T. Hintzen, Gerjan Piet, and Simon Jennings. 2014. “Evaluating Targets and Trade-Offs Among Fisheries and Conservation Objectives Using a Multispecies Size Spectrum Model.” Journal of Applied Ecology 51 (3): 612–22. https://doi.org/10.1111/1365-2664.12238.\n\n\nHartvig, Martin, Ken H. Andersen, and Jan E. Beyer. 2011. “Food Web Framework for Size-Structured Populations.” Journal of Theoretical Biology 272 (1): 113–22. https://doi.org/10.1016/j.jtbi.2010.12.006.\n\n\nICES. 2024. “Working Group on Multispecies Assessment Methods (WGSAM; Outputs from 2023 Meeting).” https://doi.org/10.17895/ices.pub.25020968.v3.\n\n\nLewy, Peter, and Morten Vinther. 2004. “A Stochastic Age-Length-Structured Multispecies Model Applied to North Sea Stocks.” ICES.\n\n\nNielsen, Anders, and Casper W. Berg. 2014. “Estimation of Time-Varying Selectivity in Stock Assessments Using State-Space Models.” Fisheries Research 158: 96–101. https://doi.org/10.1016/j.fishres.2014.01.014.\n\n\nPunt, Andre E., Doug S. Butterworth, Carryn L. de Moor, José A. A. De Oliveira, and Malcolm Haddon. 2016. “Management Strategy Evaluation: Best Practices.” Fish and Fisheries 17 (2): 303–34. https://doi.org/10.1111/faf.12104.\n\n\nScott, Finlay, Julia L. Blanchard, and Ken H. Andersen. 2014. “Mizer: An r Package for Multispecies, Trait-Based and Community Size Spectrum Ecological Modelling.” Methods in Ecology and Evolution 5 (10): 1121–25. https://doi.org/10.1111/2041-210X.12256.\n\n\nSpence, Michael A., Paul G. Blackwell, and Julia L. Blanchard. 2016. “Parameter Uncertainty of a Dynamic Multispecies Size Spectrum Model.” Canadian Journal of Fisheries and Aquatic Sciences 73 (4): 589–97. https://doi.org/10.1139/cjfas-2015-0022.\n\n\nSpence, Michael A., James A. Martindale, Khatija Alliji, Hayley J. Bannister, Robert B. Thorpe, Nicola D. Walker, Peter J. Mitchell, Matthew R. Kerr, and Paul J. Dolder. 2024. “Assessing the Effect of Multispecies Interactions on Precautionary Reference Points Using an Ensemble Modelling Approach: A North Sea Case Study.” Fisheries Research 280: 107160. https://doi.org/10.1016/j.fishres.2024.107160.\n\n\nSpence, Michael A., Robert B. Thorpe, Paul G. Blackwell, Finlay Scott, Richard Southwell, and Julia L. Blanchard. 2021. “Quantifying Uncertainty and Dynamical Changes in Multi-Species Fishing Mortality Rates, Catches and Biomass by Combining State-Space and Size-Based Multi-Species Models.” Fish and Fisheries 22 (4): 667–81. https://doi.org/10.1111/faf.12543.\n\n\nTrijoulet, Vanessa, Gavin Fay, Kiersten L. Curti, Brian Smith, and Timothy J. Miller. 2019. “Performance of Multispecies Assessment Models: Insights on the Influence of Diet Data.” ICES Journal of Marine Science 76 (6): 1464–76. https://doi.org/10.1093/icesjms/fsz053.\n\n\nTrijoulet, Vanessa, Gavin Fay, and Timothy J. Miller. 2020. “Performance of a State-Space Multispecies Model: What Are the Consequences of Ignoring Predation and Process Errors in Stock Assessments?” Journal of Applied Ecology 57 (1): 121–35. https://doi.org/10.1111/1365-2664.13515.\n\n\n\n\n",
    "preview": "posts/2025-04-02-age-in-mizer/pictures/aging_mizer_toy.png",
    "last_modified": "2025-04-02T21:01:34+01:00",
    "input_file": {},
    "preview_width": 528,
    "preview_height": 480
  },
  {
    "path": "posts/2022-12-23-mizer-240/",
    "title": "Mizer 2.4.0",
    "description": "Celebrating Christmas with a new mizer release that makes building \nrealistic multispecies models even simpler.",
    "author": [
      {
        "name": "Gustav Delius",
        "url": {}
      }
    ],
    "date": "2022-12-23",
    "categories": [],
    "contents": "\n\nContents\nAvoid confusion between maximum size and von Bertalanffy asymptotic size\nSeparate tuning of steady state and tuning of dynamics\nsetResource()\nmatchGrowth()\n\nIn time for Christmas I have a new mizer release for you. The new mizer version brings you three big changes and many small improvements.\n\nThe new version is already on CRAN, so you can update your installation with\n\n\ninstall.packages(\"mizer\")\n\n\nHowever it may take a few days until binaries are available for all platforms, so if you are not set up to compile R packages from source you may want to try the above again after Christmas.\nAfter you have updated to mizer 2.4.0 you will also want to update the mizerExperimental package with\n\n\nremotes::install_github(\"sizespectrum/mizerExperimental\")\n\n\nThis release introduces a change that requires you to upgrade your old MizerParams and MizerSim objects with upgradeParams() or upgradeSim(). Let’s assume that you have an existing MizerParams object named params. Then to use it with the new version of mizer you would do\n\n\nparams <- upgradeParams(params)\n\n\nSimilarly, if you have a MizerSim object called sim you would do\n\n\nsim <- upgradeSim(sim)\n\n\nNothing bad will happen if you forget to do this, but mizer will keep reminding you. Also, you need to\nI’ll now discuss the three big changes. You can always see the smaller changes in the Changelog on the mizer website.\nAvoid confusion between maximum size and von Bertalanffy asymptotic size\nAs I explained in the previous blog post Don’t use von Bertalanffy growth parameters, in the past mizer confused the von Bertalanffy growth curve and the mizer growth curve, even though they are very different things. In particular, the mizer documentation advised you to use the asymptotic size parameter of the von Bertalanffy curve as the size at which a species invests 100% of its income into reproduction. The new version finally fixes this.\nThe species parameter that specifies the size at which also the largest fish stop growing is renamed from w_inf to w_max. The parameter w_inf is now reserved for the von Bertalanffy asymptotic size parameter. If you upgrade your existing MizerParams object with upgradeParams() the w_inf column is copied over to the w_max column automatically, but you may want to change the values yourself if they do not currently reflect the maximum size of the species. Otherwise the size distributions predicted by mizer will not match observations.\nSeparate tuning of steady state and tuning of dynamics\nAlready mizer 2.0 introduced the idea that building a new mizer model should be done in two stages. In the first stage one adjusts the species parameters so that the model has steady state spectra and steady state yields that roughly agree with averaged observations. Only in the second stage one adjusts the density dependence in the model, i.e., one tunes the sensitivity of the model to changes. This separation between these two stages is similar to the separation between Ecopath and Ecosim.\nThere are three tunable sources of density dependence in mizer:\nThe reproduction level. This is the ratio between the actual rate of reproduction and the maximal rate of reproduction R_max. The higher the reproduction level, the less sensitive the species is to changes in its spawning stock biomass.\nThe resource level. This is the ratio between the actual resource abundance and the resource carrying capacity. The higher the resource level the less sensitive the model is to competition among the larvae of the fish species for the limited resource.\nThe feeding level. This is the ration between the rate at which individuals take in food and their maximum intake rate. The higher the feeding level, the less sensitive a species is to competition for prey. We’ll discuss this below when we talk about growth rates.\nIdeally one would like to be able to tune each of these in the second stage of model calibration without spoiling the steady state calibration from the first stage of the process. Mizer 2.0 already introduced the setBevertonHolt() function that allows one to tune the reproduction level without changing the steady state. Now in mizer 2.4 the setResource() function allows you to also tune the resource level without changing the steady state. While you still can’t change the feeding level without changing the steady state, at least the new matchGrowth() function allows you to keep reasonable growth rates after changing the feeding level.\nsetResource()\nWhile tuning the steady state using the steady() function the resource abundance is now being kept fixed at the chosen value. Then, once the steady state is to your satisfaction, you can turn on the resource dynamics with setResource() without changing the steady state.\nLer’s assume we are happy with the steady state of the NS_params model that comes with mizer (there are many reasons not to be happy with it yet and mizer 2.5 whould definitely ship with a better example model, but let’s ignore that for now).\n\n\nparams <- steady(NS_params, tol = 1e-10)\nplotlySpectra(params, power = 2)\n\n\n\nThen\n\n\nparams2 <- setResource(params, resource_level = 0.5)\n\n\nwill set the carrying capacity to twice the resource abundance at all sizes and at the same time it will set the resource replenishment rate so that the replenishment balances the consumption of the resource.\nLet us verify that in spite of changing the resource level we are still at steady state:\n\n\nsim2 <- project(params2, t_max = 10)\nplotlyBiomass(sim2)\n\n\n\nSo, given that changing the resource level does not actually change any abundances and leaves us at the same steady state as before, what is the point?\nThe point is that the system will react differently to changes. As an example, we will investigate the effect of an industrial fishery targeting the small pelagics in the North Sea. The North Sea model is currently set up with an effort of 0 for the industrial gear:\n\n\neffort <- params@initial_effort\neffort\n\nIndustrial    Pelagic       Beam      Otter \n       0.0        1.0        0.5        0.5 \n\nThe target species of the industrial gear are Sprat, Sandeel and N.pout:\n\n\ngear_params(params) |> filter(gear == \"Industrial\") |>\n    select(catchability)\n\n                    catchability\nSprat, Industrial              1\nSandeel, Industrial            1\nN.pout, Industrial             1\n\nWe can now turn on the industrial gear, setting its effort to 1, and see how that impacts the biomasses of the different species in the future:\n\n\neffort[\"Industrial\"] <- 1\nsim <- project(params, effort = effort, t_max = 15)\nplotlyBiomassRelative(sim)\n\n\n\nNot surprisingly, the target species are suffering. But there are also impacts on the other species. For example Gurnard increases by about 17%, presumably due to decreased competition with the small pelagics. It is of course these multi-species effects that we are particularly interested in being able to model in mizer. So it is important to explore how these effects are affected by the resource dynamics. So now we run exactly the same simulation but with the params object in which we had set the resource level to 0.5 while keeping exactly the same steady state.\n\n\nsim2 <- project(params2, effort = effort, t_max = 15)\nplotlyBiomassRelative(sim2)\n\n\n\nBy decreasing the resource level we have increased the competition for resource among the species. Fishing the small pelagics has decreased their biomasses and they thus consume less resource. Some species like Herring profit enormously from this.\nIf you want to keep the old behaviour and switch off this automatic balancing you have to add the balance = FALSE argument when calling setResource().\nThe arguments kappa and lambda in newMultispeciesParams() are now used to set the abundance of the resource in the steady state rather than the carrying capacity. This is in any case more useful because you may have observations about the resource abundance whereas the resource carrying capacity is unobservable.\nAnother addition in mizer 2.4.0 is that you can choose between semichemostat dynamics resource_semichemostat() or logistic dynamics resource_logistic(). To switch to logistc dynamics you would do\n\n\nparams3 <- setResource(params, \n                       resource_dynamics = \"resource_logistic\", \n                       resource_level = 0.3)\n\n\nYou can of course choose any value between 0 and 1 for the resource level.\nInvestigating resource dynamics other than semichemostat is interesting because semichemostat dynamics are particularly stable and the real world may not be as accommodating. For example in logistic dynamics, if the resource level drops below 1/2, the replenishment rate decreases as the abundance decreases, which is of course destabilising. Take a look:\n\n\nsim3 <- project(params3, effort = effort, t_max = 60)\nplotlyBiomassRelative(sim3)\n\n\n\nOf course you can also still write your own function implementing more sophisticated resource dynamics.\nmatchGrowth()\nIn the previous blog post Don’t use von Bertalanffy growth parameters, I discussed that the von Bertalanffy curves fitted to size-at-age data are not suitable for estimating the size-dependent growth rates in mizer. I therefore now recommended that instead of von Bertalanffy parameters you supply the age at maturity in the age_mat column of the species parameter data frame. Mizer will then use that to calculate a default for the maximum intake rate parameter h if you do not supply this.\nIn the past, whenever you changed any model parameters, you needed to re-tune other parameters to keep the growth rates in line with observations. There is now a new function matchGrowth() that automatically scales the search volume, the maximum consumption rate and the metabolic rate all by the same factor in order to achieve a growth rate that allows individuals to reach their maturity size by their maturity age while keeping the feeding level and the critical feeding level unchanged. This function does not however preserve the steady state, so you will need to also call steady() after matching the growth rates.\nThis allows us for example to change the feeding level without spoiling the growth rates. Let’s do an example. We double the maximum intake rate for Cod, and this of course gives it a lower feeding level:\n\n\nparams4 <- params\nspecies_params(params4)[\"Cod\", \"h\"] <- species_params(params)[\"Cod\", \"h\"] * 2\nplotlyFeedingLevel(params4)\n\n\n\nHowever this also spoiled the growth rate for Cod. We can fix that with matchGrowth() followed by steady().\n\n\nparams4 <- params4 |> matchGrowth() |> steady()\nplotlyFeedingLevel(params4)\n\n\n\nNormally you will want to also keep biomasses at the observed level, for which already mizer 2.3.0 provided the matchBiomasses() function. So often you will run all three in a row. So the pattern is:\n\n\n# make some changes to the model parameters and then find a new steady state\n# with the correct growth rates and abundances with\nparams <- params |> matchGrowth() |> matchBiomasses() |> steady()\n\n\nThere is of course a lot more to say. But first there is Christmas to celebrate. Even if your cultural background does not dictate that you celebrate Christmas, I hope you will have some quality time to spend with your friends and family.\n\n\n\n",
    "preview": "posts/2022-12-23-mizer-240/images/Christmas_tree_mizer.png",
    "last_modified": "2024-12-18T15:34:55+00:00",
    "input_file": {},
    "preview_width": 666,
    "preview_height": 754
  },
  {
    "path": "posts/2022-11-30-dont-use-von-bertalanffy-growth-parameters/",
    "title": "Don't use von Bertalanffy growth parameters",
    "description": "Beware of the difference between age-dependent growth curves and the \nsize-dependent growth curves used by mizer.",
    "author": [
      {
        "name": "Gustav Delius",
        "url": {}
      }
    ],
    "date": "2022-11-30",
    "categories": [],
    "contents": "\n\nContents\nEstimating von Bertalanffy parameters\nAge-dependent growth rate\nSize-dependent growth rate\nSize-based growth curve\nSo what should you do?\nMaximum size\nMaximum intake rate\n\n\nThis blog post is not about criticising the von Bertalanffy growth model or the methods used to estimate the von Bertalanffy parameters from size-at-age data. There is a lot of literature about that. This blog post is about the difference between age-dependent and size-dependent growth rates. In the past we had mis-used the age-based von Bertalanffy growth species parameters w_inf and k_vb when setting up mizer models and this blog posts explains why that was a bad idea.\nA von Bertalanffy growth curve is an expression for the length \\(L\\) of an average fish of age \\(a\\):\n\\[\nL(a) = L_\\infty\\left(1-e^{-K(a-t_0)}\\right).\n\\]\nThe constants \\(L_\\infty, K\\) and \\(t_0\\) are the von Bertalanffy growth parameters.\nWe can teach R about this with\n\n\nlength_vB <- function(age, Linf, K, t0) {\n    Linf * (1 - exp(-K * (age - t0)))\n}\n\n\nIf we assume a length-weight relationship of the form \\(w = a L^b\\) then we get an expression for the weight as a function of age:\n\\[\nw(a) = w_\\infty\\left(1-e^{-K(a-t_0)}\\right)^b\n\\]\nwith the same parameters \\(K\\) and \\(t_0\\) and \\(w_\\infty = aL_\\infty^b\\).\nThe von Bertalanffy growth model is quite simple as a deterministic model of growth. The issue becomes complicated only because growth in the real world is not deterministic. Different fish, even in the same stock, have different luck in finding food and they also have different genes. So the von Bertalanffy growth curve is used to describe average fish. Whenever one hears the word “average”, on needs to be very careful that one knows how that average is taken.\nHere is the short summary of the main message from this blog post:\n\nThe von Bertalanffy parameters describe the growth averaged over all fish of the same age, as is appropriate in age-based models. Mizer is a size-based model and hence needs the growth averaged over all fish of the same size. This makes it inappropriate to use the von Bertalanffy parameters when calibrating a mizer model.\n\n\nIn particular, the von Bertalanffy parameter \\(w_\\infty\\) is the asymptotic size of an average individual whereas the mizer parameter w_inf is the asymptotic size of the largest individual. A mizer model that uses estimated values for \\(w_\\infty\\) as the value for w_inf will predict that there are no fish larger than \\(w_\\infty\\) and thus can not reproduce the observed size distributions.\n\nThe message about the difference between the growth rate of an average individual of a particular age and the growth rate of an average individual of a particular size can also be important outside of mizer, for example when using size-resolved data to estimate the productivity of a species.\nThe remainder of this blog post is just about illustrating the above message. In particular, it makes it concrete what we mean by averaging at a fixed age or averaging at a fixed size. That is, we demonstrate the difference between fitting a curve by minimising the squared difference between observed size and predicted size and fitting a curve by minimising the squared difference between observed age and predicted age.\nIf you just want to know what you can use instead of the von Bertalanffy parameters you can jump straight to “So what should you do?”\nEstimating von Bertalanffy parameters\nThe von Bertalanffy growth parameters are usually obtained by fitting the von Bertalanffy curve to size-at-age data. For a good introduction I recommend the fishR vignette. To illustrate this we will use the Croaker2 data set contained in the FSAdata package. The data consists of observations of the lengths and ages of a sample of fish.\n\n\nlibrary(tidyverse)\ndf <- FSAdata::Croaker2 |>\n    select(age = age, length = tl) |>\n    filter(age > 0) |>\n    na.omit()\npl <- ggplot(df) +\n    geom_jitter(aes(x = age, y = length))\npl\n\n\n\nIn this scatterplot each point shows the length and age of one croaker from our sample.\nThe standard method to fit a von Bertalanffy curve to such a point cloud of size-at-age observations is the method of least squares. This consists of choosing the parameters so as to minimise the sum of the squares of the differences between the the observed lengths and the length predicted by the von Bertalanffy curve. So if we denote the length measurements by \\(L_i\\) and the corresponding age measurements by \\(a_i\\) then we want to minimise\n\\[ \\sum_i (L_i - L(a_i))^2\\]\nwhere the sum is over all fish in our sample.\nTo find the minimum, we will use the function optim(). First we create a function that calculates the sum of squares when given a vector with the parameters:\n\n\nsum_of_squares <- function(par, df) {\n    Linf <- par[[1]]\n    K <- par[[2]]\n    t0 <- par[[3]]\n    sum((df$length - length_vB(df$age, Linf, K, t0))^2)\n}\n\n\nWe need to give an initial guess for the parameters to optim, as well as lower bounds on the parameter values.\n\n\nstart <- list(Linf = 400, K = 0.3, t0 = 0)\nlower <- list(Linf = 0, K = 0.01, t0 = -4)\n\n\nIt does not matter too much what the initial guess is as long as it is not too wrong. The lower bound is needed to keep the optimizer from trying negative values for \\(K\\). Now we can call optim(). (We use the method “L-BFGS-B” because that is the only built-in method that handles bounds on the parameters.)\n\n\nop_age <- optim(start, fn = sum_of_squares, \n            df = df, lower = lower, \n            method = \"L-BFGS-B\")\nop_age$par\n\n       Linf           K          t0 \n416.0794061   0.2423941  -2.1629160 \n\nLet us plot the von Bertalanffy curve with these parameters on top of or observations:\n\n\npl <- pl +\n    geom_function(fun = length_vB, args = as.list(op_age$par),\n                  linewidth = 2, colour = \"blue\")\npl\n\n\n\nAt each age the fitted von Bertalanffy curve approximates the average of the lengths of all the fish of that age.\nOf course, the curve is only made to fit the data in the observed size range. The curve clearly does not extrapolate well to larval sizes as we can see from the large negative value of \\(t_0\\). This becomes clearer if we extend the age range of the plot.\n\n\npl + xlim(0, 12) +\n    geom_hline(yintercept = op_age$par[[\"Linf\"]], \n               colour = \"blue\", linetype = \"dashed\")\n\n\n\nThe curve would predict a length of more than 170cm at birth, which is clearly nonsense. The larval growth must be much faster than predicted by the von Bertalanffy curve. That is why mizer works with a bi-phasic growth model, but that is not our current topic.\nIn the above plot we also indicated the average asymptotic length \\(L_\\infty\\) with a dashed blue line. What will be important for us is to note that this is the average asymptotic length and that there are a lot of fish with a length larger than \\(L_\\infty\\).\nThere are many issues that we could debate and that have been debated at length in the literature:\nIs the von Bertalanffy growth model the best growth model.\nHow reliably can the growth be estimated from the size-at-age data.\nIs least squares estimation an appropriate method.\nBut none of these are our topic. We will assume that the von Bertalanffy curve gives an appropriate representation of the length at age of an average fish of that age.\nAge-dependent growth rate\nThe slope of the von Bertalanffy curve at age \\(a\\) gives the average growth rate of fish of that age:\n\\[\\frac{dL(a)}{dt}=\\frac{dL(a)}{da}=K\\, L_\\infty\\, e^{-K(a-t_0)}\n= K(L_\\infty - L(a)).\\] (We used that time \\(t\\) and age \\(a\\) increase together, \\(da/dt=1\\).)\nThe important point to understand is that this is the growth rate as a function of age. The length \\(L(a)\\) that enters the expression is the average length of fish of age \\(a\\). This is useful information in age-based population models. It is not useful in size-based models like mizer.\nSize-dependent growth rate\nWe want the average growth rate for fish of some given length \\(L\\) rather than the average growth rate for fish of a given age \\(a\\). Why? There can be several reasons.\nAssume for example that we want to estimate the productivity of a population and have only information about the size distribution of the population. Such size data is often more readily available than age data because length or weight measurements are easy while age determination is difficult and time consuming. If we have the average growth rate of fish as a function of size then we can multiply that by the abundance of fish of that size and sum over all sizes to get the total productivity.\nMore relevantly to us, the mizer model is a size-based model that uses the growth rate as a function of size to project the size distribution into the future. Mizer of course can calculate this growth rate itself with its getEGrowth() function. However it would be good if one had an observed growth rate to compare to to calibrate the species parameters in mizer that influence the mizer growth rate.\nOne might think that the above equation also gives an expression for the average growth rate for fish of length \\(L\\). Can’t we simply replace the \\(L(a)\\) by \\(L\\)?\n\\[\\frac{dL}{dt} \\stackrel{?}{=} K(L_\\infty - L).\\]\nWe can’t. If we try that, then at all \\(L\\) above \\(L_\\infty\\) the formula gives a negative growth rate. But that is not how fish work. Fish that are lucky enough to grow beyond the average asymptotic size \\(L_\\infty\\) are not compelled to shrink back to average size.\nWhat we need to realise is that in fitting the von Bertalanffy curve to the size-at-age data we did not treat size and age equally. Rather we chose to average over all sizes at fixed age. From that averaged data we can not reconstruct the information about what happens at a specific size.\nSize-based growth curve\nWe now understand that from a curve describing the average size of all fish of a certain age we can not deduce the average age of all fish of a certain size and hence we can not use it to determine the growth rate as a function of size. What we would need is a curve describing the average age of all fish of a certain size. Let’s refer to that as a size-based growth curve as opposed to an age-based growth curve.\nNow we want to discuss how we can determine a size-based growth curve from size-at-age data. This should be possible. If the size-at-age data comes from a random sample of fish for each of which its size and age were measured, then the data treats size and age the same. It was only our least squares fit that singled out age as the explanatory variable and size as the variable to average over. We now simply have to reverse the roles of size and age.\nWe’ll again use the von Bertalanffy growth model, in the sense of assuming that the growth rate decreases linearly with length,\n\\[\\frac{dL}{dt} = K(L_{max}-L),\\]\nbut now we interpret this as the growth rate of an average individual of size \\(L\\). This immediately implies that the parameter \\(L_{max}\\) is the length of the largest individual in the population. We can use that growth rate to express the age as a function of length instead of expressing length as a function of age. This gives the expression\n\\[\na(L) = t_0 - \\frac{1}{K}\\log\\left(1-\\frac{L}{L_{max}}\\right).\n\\]\nThis expression of course has a singularity at \\(L = L_{max}\\) because even if a fish lived for an infinite amount of time it would not grow beyond \\(L_{max}\\). Dealing with that singularity in the expression numerically would be challenging, so we acknowledge that fish are never going to live infinitely long and therefore \\(L\\) will never quite reach \\(L_{max}\\) and so we can cut of the curve when \\(L\\) gets sufficiently close to \\(L_{max}\\).\n\n\nage_vB <- function(L, Lmax, K, t0) {\n    r <- pmin(L / Lmax, 0.999999)\n    t0 - log(1 - r) / K\n}\n\n\nInstead of choosing the parameters so as to minimize the sum of squares of the difference between the observed lengths and the predicted lengths, we minimize the sum of squares of the difference between the observed ages and the predicted ages. The function calculating the sum of squares is now\n\n\nsum_of_squares <- function(par, df) {\n    Lmax <- par[[1]]\n    K <- par[[2]]\n    t0 <- par[[3]]\n    sum((df$age - age_vB(df$length, Lmax, K, t0))^2)\n}\n\n\nBecause all observations must be strictly shorter than \\(L_{max}\\) we need to start optim with a starting value for \\(L_{max}\\) that is above the largest observed length.\n\n\nstart <- list(Lmax = max(df$length) * 1.2, K = 0.3, t0 = 0)\nlower <- list(Lmax = 0, K = 0.01, t0 = -4)\nop_length <- optim(start, fn = sum_of_squares, df = df, \n            lower = lower, method = \"L-BFGS-B\")\nop_length$par\n\n         Lmax             K            t0 \n1235.69702683    0.04733173   -1.22046772 \n\nWe can now again visualise this curve by plotting it on top of the point cloud of observations:\n\n\npl <- ggplot(df) +\n    geom_jitter(aes(x = length, y = age)) +\n    geom_function(fun = age_vB, args = as.list(op_length$par),\n                  linewidth = 2, colour = \"blue\")\npl\n\n\n\nGiven that we are now dealing with the size-based growth curve, we plot the length on the x axis and the age on the y axis.\nI am not saying that fitting a von Bertalanffy curve to the average growth at size via least squares is a good idea. I am showing it only to compare to the fitting of a von Bertalanffy curve to the average growth at age that is commonly done. I think that a bi-phasic growth model like that used in mizer is more appropriate.\nOne problem with the von Bertalanffy curve is that there is a wide range of maximum sizes that can fit the data almost equally well. For example we may find that the maximum length of 1236cm predicted by the least squares fit is unrealistic and set an upper bound of 600cm:\n\n\nupper <- list(Lmax = 600, K = 0.5, t0 = 4)\nop_length_2 <- optim(start, fn = sum_of_squares, df = df, \n            lower = lower, upper = upper, method = \"L-BFGS-B\")\nop_length_2$par\n\n       Lmax           K          t0 \n600.0000000   0.1838247   0.9216962 \n\nThat leads to totally different values for \\(K\\) and \\(t_0\\) but the fit is almost as good:\n\n\npl + geom_function(fun = age_vB, args = as.list(op_length_2$par),\n                   linewidth = 2, colour = \"green\")\n\n\n\nSo what should you do?\nWe have now understood that to estimate the size-dependent growth rate you should not use the age-based von Bertalanffy parameters, even though they are routinely used in age-based models and are therefore often readily available. So what do I propose you use instead for your species parameters when setting up a mizer model?\nMaximum size\nI propose that for the maximum size parameter w_inf you use the largest observed size. If necessary you can obtain this from FishBase. FishBase gives the maximum length in cm, so you also need the length-weight conversion parameters a and b to get he maximum weight in grams. Here is an example:\n\n\nspecies <- c(\"Gadus morhua\", \"Sprattus sprattus\")\nlength_weight <- rfishbase::estimate(species) |>\n    select(\"Species\", \"a\", \"b\")\nmax_length <- rfishbase::species(species) |>\n    select(Species, Length)\nmax_weight <- left_join(max_length, length_weight) |>\n    mutate(w_inf = a * Length ^ b)\nmax_weight\n\n# A tibble: 2 × 5\n  Species           Length       a     b   w_inf\n  <chr>              <dbl>   <dbl> <dbl>   <dbl>\n1 Gadus morhua         200 0.00692  3.08 84561. \n2 Sprattus sprattus     16 0.00550  3.09    28.9\n\nMaximum intake rate\nTo determine a good value for the coefficient h of the maximum intake rate in mizer I recommend using the size and age at maturity. For that you need both a w_mat (in grams) and an age_mat (in years) column in your species parameter data frame.\nIf necessary, you can look up values for the maturity length and maturity age on fishbase. For example\n\n\nmaturity_tbl <- rfishbase::maturity(\"Sprattus sprattus\") |>\n    select(Species, l_mat = Lm, age_mat = tm, Locality) |>\n    na.omit()\nmaturity_tbl\n\n# A tibble: 4 × 4\n  Species           l_mat age_mat Locality                            \n  <chr>             <dbl>   <dbl> <chr>                               \n1 Sprattus sprattus 11.5     2    North Sea                           \n2 Sprattus sprattus  8.10    1.20 Baltic Sea, Sub-divisions 22-32, 20…\n3 Sprattus sprattus 12       2    Baltic Sea                          \n4 Sprattus sprattus  8.10    1.20 Baltic Sea, sub-divisions 22-32     \n\nYou can then select the row most suitable for your purposes and convert the maturity length to maturity weight. Then you can determine the value for h that will create the juvenile growth necessary to reach the maturity size by the maturity age with the mizerExperimental::get_h_default() function. In the next release of mizer calling this function will no longer be necessary because mizer will use it by default if you do not include an h column in your species parameters.\nThe next release of mizer will also encourage the use of the column name w_max instead of w_inf to avoid the confusion with the age-based von Bertalanffy parameter and it will issue a warning if you use the k_vb column in the species parameter data frame. The help pages will be updated accordingly.\nIf you have good size-at-age data then you will of course want to use it to also extract information about the shape of the growth curve between maturity and maximum size. This would for example allow you to get information about how fast the investment into reproduction increases with body size. For this purpose it is important that you have access to the actual size-at-age data, not its age-based summary in terms of von Bertalanffy parameters.\n\n\n\n",
    "preview": {},
    "last_modified": "2024-12-18T15:34:55+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-07-11-thermizer/",
    "title": "Temperature-dependent rates in mizer",
    "description": "Temperature is an important driver of ecosystem change.  Now you can include it in mizer.",
    "author": [
      {
        "name": "Phoebe Woodworth-Jefcoats",
        "url": "https://www.fisheries.noaa.gov/contact/phoebe-woodworth-jefcoats"
      }
    ],
    "date": "2022-07-11",
    "categories": [],
    "contents": "\n\nContents\nIntroduction\nAerobic\nscope\nMetabolic\nrate\n\nModel input\nA simple\nsimulation\nAdapting this for a\ndata-based simulation\nIn the works\nAcknowledgements\nUpdate note\nReferences\n\nIntroduction\ntherMizer models the effects of temperature on individuals’ aerobic\nscope and metabolic rate using an approach that requires minimal\nparameterization. This allows you to easily incorporate dynamic\ntemperature-dependent rates into mizer, enabling simulations to include\nan important climate-related driver.\nAerobic scope\nThe relationship between aerobic scope and temperature is a somewhat\nleft-skewed distribution with a thermal optimum and upper and lower\nthermal tolerance limits. Pörtner and Peck\n(2010) provide an overview of this relationship and Pörtner (2012) discusses\nopen questions related to temperature and physiology. The exact nature\nof the relationship between aerobic scope and temperature varies by\nspecies and requires a fair bit of physiological research to establish.\nTherefore, it is generally necessary to approximate this relationship,\nwhich is what therMizer does. A generic polynomial rate equation is used\nto approximate the effect of temperature on aerobic scope, s:\n\\[\\begin{align}\ns = T(T - T_{min})(T_{max} - T)^\\frac{1}{2} && \\text{(1)}\n\\end{align}\n\\] where T is the temperature to which a fish is exposed\nand \\(T_{max}\\) and \\(T_{min}\\) are the species’ upper and lower\nthermal tolerance limits, respectively (van der Heide et\nal. 2010). All temperatures in eq. (1) are in Kelvin. The result of\nthis expression varies considerably given a species’ thermal tolerance\nlimits. Therefore, it is necessary to scale this value across all\nmodeled species so that it equals a value ranging from 0 – 1. This is\ndone by dividing by the maximum value over each species’ thermal range\n(Woodworth-Jefcoats\net al. 2019). therMizer will take care of this scaling for you.\nThe scaled value is then used as a multiplier for encounter rate and\npredation rate in mizer. The scaling is applied to encounter rate as\nproxy for foraging movement. The resulting temperature effect is such\nthat when species are at their thermal optima they realize peak aerobic\nperformance and encounter the maximum amount of prey possible. This\nability diminishes to either side of the optimum and reaches zero\noutside species’ thermal tolerance limits. The scaling is applied to\npredation rate to ensure encountered prey are predated upon.\nMetabolic rate\nThe relationship between metabolic rate and temperature is\nexponential and positive (see, for example, Brown et al. 2004). To\nsimulate this, therMizer uses a Boltzmann factor or Arrhenius relation:\n\\[\n\\begin{align}\nr = e^{25.22-\\frac{E}{kT}} && \\text{(2)}\n\\end{align}\n\\] where r is the effect of temperature on metabolic\nrate, E is activation energy (0.63 eV), k is\nBoltzmann’s constant (\\(8.62 \\times\n10^{-5}\\) eV K\\(^{-1}\\)), and\nT is temperature in Kelvin (Brown et al. 2004, Jennings et al. 2008).\nThe result of this expression varies depending upon the temperature to\nwhich species are exposed, which is in turn a factor of species’ thermal\ntolerance limits. Therefore, it is necessary to scale this value across\nall species so that it equals a value ranging from 0 – 1. This is done\nby subtracting the minimum value over each species’ thermal range and\nthen dividing the result by the range (Woodworth-Jefcoats\net al. 2019). therMizer will take care of this scaling (and\nconverting from degrees C to Kelvin) for you when you.\nThe scaled value is then used as a multiplier for standard metabolism\nin therMizer. This has the effect of metabolism being the least\nexpensive when species are at the low end of their thermal tolerance and\nthe most expensive at the upper limits of their thermal tolerance.\nFinally, therMizer sets the rate scalings to 0 outside species’\nthermal range, simulating the assumption that species would move out of\nwaters that are either too warm or too cool.\nModel input\nThe only additional input you’ll need to provide, beyond what’s\nneeded to run mizer, are three temperature values for each species.\ntemp_min and temp_max represent the lower and\nupper bounds of a species’ thermal tolerance limits. You can find this\ninformation in the literature or in databases such as rfishbase (Boettiger et\nal. 2012). You also need to provide ocean_temp, the\ntemperature to which species are exposed. This can be static or dynamic,\nand informed from either empirical or modeled data. Temperatures are\ninput in degrees Celsius. therMizer will convert them to Kelvin.\nThat’s it. That’s all you need.\nA simple simulation\nLet’s do a simple simulation with two fictional fish species. We’ll\nneed to invent some parameters for them:\n\n\nlibrary(mizer)\n\nspecies_params <- \n    data.frame(species = c(\"speciesA\", \"speciesB\"), \n               w_inf = c(500, 5000), \n               k_vb = c(0.8, 0.3), \n               w_min = c(0.001, 0.001), \n               beta = c(1000,100), \n               sigma = c(3,3))\nspecies_params$interaction_resource <- c(1,0.5)\nparams <- newMultispeciesParams(species_params, no_w = 200, kappa = 0.0001) |> \n    steady(tol = 0.001)\n\n\nAdd their hypothetical thermal tolerance limits:\n\n\nspecies_params(params)$temp_min <- c(15, 10)\nspecies_params(params)$temp_max <- c(25, 20)\n\n\nAnd, finally, the temperatures to which each species is exposed. To\nmake it interesting, we’ll have one species eventually encounter\ntemperatures beyond its thermal tolerance limits.\n\n\n# Create temperature array and fill it\ntimes <- 0:500\nspecies <- species_params(params)$species\nocean_temp_array <- array(NA, dim = c(length(times), length(species)), \n                          dimnames = list(time = times, sp = species))\ntemp_inc <- 0\nfor (i in 1:501) {\n  ocean_temp_array[i,] <- c(17 + temp_inc, 17 + temp_inc)\n  temp_inc <- temp_inc + 0.01\n}\nother_params(params)$ocean_temp <- ocean_temp_array\n\n\nNow that we’ve put in all the necessary temperature information, we\ncan add the code that tells mizer how to use it. First, the parameters\nneeded to do the scaling that’s mentioned above:\n\n\n# Create parameter for scaling encounter and mortality rates\nspecies_params(params)$encounterpred_scale <- \n    rep(NA, nrow(species_params(params)))\n\nfor (indv in seq(1:length(species_params(params)$temp_min))) {\n    \n    # Create a vector of all temperatures each species might encounter\n    temperature <- seq(species_params(params)$temp_min[indv], \n                       species_params(params)$temp_max[indv], \n                       by = 0.1) + 273\n    \n    # Find the maximum value of the unscaled effect of temperature on encounter\n    # and predation rate for each species \n  species_params(params)$encounterpred_scale[indv] <- \n      max((temperature) * \n              (temperature - (species_params(params)$temp_min[indv] + 273)) *\n              ((species_params(params)$temp_max[indv] + 273) - temperature)^(1/2)\n          )\n}\n\n# Determine the minimum, maximum, and range of value for the effect of \n# temperature on metabolism\n    \nmin_metab_value <- \n    (exp(25.22 - (0.63/((8.62e-5)*(273 + species_params(params)$temp_min)))))\nmax_metab_value <- \n    (exp(25.22 - (0.63/((8.62e-5)*(273 + species_params(params)$temp_max)))))\n    \nspecies_params(params)$metab_min <- min_metab_value\nspecies_params(params)$metab_range <- max_metab_value - min_metab_value\n\n\nThen, we can add code to scale encounter rate and predation rate\nbased on the temperature at a given time step:\n\n\n# Calculate the temperature scaling factor for the encounter rate and \n# predation rate\nscaled_temp_effect <- function(t) {\n    # Using t+1 to avoid calling ocean_temp[0,] at the first time step\n    temp_at_t <- other_params(params)$ocean_temp[t + 1,] + 273\n    \n    # Calculate unscaled temperature effect using a generic polynomial rate equation\n    unscaled_temp_effect <- \n        temp_at_t * (temp_at_t - (species_params(params)$temp_min + 273)) * \n        ((species_params(params)$temp_max + 273) - temp_at_t)^(1/2)\n    \n    # Scale using new parameter\n    scaled_temp_effect <- \n        unscaled_temp_effect / species_params(params)$encounterpred_scale\n    \n    # Set temperature effect to 0 if temperatures are outside thermal \n    # tolerance limits\n    above_max <- (temp_at_t - 273) > species_params(params)$temp_max\n    below_min <- (temp_at_t - 273) < species_params(params)$temp_min\n    scaled_temp_effect[above_max | below_min] = 0\n    \n    scaled_temp_effect\n}\n\n\ntherMizerEncounter <- function(params, t, ...) {\n    \n      # Calculate maximum possible encounter rate\n      max_encounter <- mizerEncounter(params, t, ...)\n      \n      # Apply temperature effect\n      return(max_encounter * scaled_temp_effect(t))\n      \n}\n\ntherMizerPredRate <- function(params, t, ...) {\n      # Calculate maximum possible encounter rate\n      max_predrate <- mizerPredRate(params, t, ...)\n      \n      # Apply temperature effect\n      return(max_predrate * scaled_temp_effect(t))\n      \n}\n\n\nAs well as metabolic rate:\n\n\ntherMizerEReproAndGrowth <- function(params, t, encounter, feeding_level, ...) {\n    \n    # Using t+1 to avoid calling ocean_temp[0,] at the first time step\n    temp_at_t <- other_params(params)$ocean_temp[t + 1,]\n  \n    # Arrhenius equation\n    unscaled_temp_effect <- (exp(25.22 - (0.63/((8.62e-5)*(273 + temp_at_t)))))\n    \n    # Arrhenius equation scaled to a value between 0 and 1\n    temp_effect_metabolism <- \n        (unscaled_temp_effect - species_params(params)$metab_min) /\n        species_params(params)$metab_range\n    \n    # Set temperature effect to 0 if temperatures are outside thermal \n    # tolerance limits\n    above_max <- temp_at_t > species_params(params)$temp_max\n    below_min <- temp_at_t < species_params(params)$temp_min\n    temp_effect_metabolism[above_max | below_min] = 0\n  \n  # Apply scaled Arrhenius value to metabolism\n    sweep((1 - feeding_level) * encounter, 1,\n          species_params(params)$alpha, \"*\", check.margin = FALSE) - \n        metab(params)*temp_effect_metabolism  \n      \n}\n\n\nFinally, we need to replace mizer’s rate functions with our new\ntemperature-dependent rate functions:\n\n\nparams <- setRateFunction(params, \"Encounter\", \"therMizerEncounter\")\nparams <- setRateFunction(params, \"PredRate\", \"therMizerPredRate\")\nparams <- setRateFunction(params, \"EReproAndGrowth\", \"therMizerEReproAndGrowth\")\n\n\nLet’s see what a simulation looks like.\n\n\nsim <- project(params, t_max = 500, effort = 0) \nplot(sim)\n\n\n\nAdapting this for a\ndata-based simulation\nYou’re likely going to want to do simulations based on real species\nand real temperature observations or projections. This is\nstraightforward to do. When you prepare your species parameters, add\ntemp_min and temp_max columns for each\nspecies. You’ll also need to prepare an ocean_temp input\nwith dimensions that match those of time and\nspecies.\nOnce you’ve prepared your input, you can use the code above to create\nand use the encounterpred_scale, metab_min,\nand metab_range parameters and the\ntherMizerEncounter, therMizerPredRate, and\ntherMizerEReproAndGrowth rate functions.\nIn the works\nMany fish undergo ontogentic migration, spending different life\nstages at different depths and therefore different thermal habitats. I’m\nworking on adding to therMizer the capacity for different size classes\nto experience different temperatures.\nAcknowledgements\nThis blog post was compiled with mizer version 2.3.1 and R version\n4.2.1. Many thanks to Gustav Delius for guidance on mizer’s inner\nworkings and writing better code. Thank you also to Romain Forestier for\ninsight on working with temperatures below 0\\(^\\circ C\\).\nUpdate note\nPost updated on 19/09/22: The equation for aerobic scope was changed\nto allow users to input negative Celsius temperature. To accommodate\nthis, temperatures are now converted to Kelvin and the square root of\nthe final polynomial term is taken to preserve the curve shape.\nReferences\nBoettiger C, Lang DT, Wainwright PC. (2012) rfishbase: exploring,\nmanipulating, and visualizaing FishBase from R. Journal of Fish Biology\n81, 2030–2039. https://doi.org/10.1111/j.1095-8649.2012.03464.x\nBriere J-F, Pracros P, Le Roux A-Y, Pierre J-S. (1999) A novel rate\nmodel of temperature-dependent development in arthropods. Population\nEcology, 28(1): 22-29. https://doi.org/10.1093/ee/28.1.22\nBrown JH, Gillooly JF, Allen AP, Savage VM, West GB. (2004) Toward a\nmetabolic theory of ecology. Ecology, 85: 1771–1789. https://doi.org/10.1890/03-9000\nJennings S, Mélin F, Blanchard JL, Forster RM, Dulvy NK, Wilson RW.\n(2008) Global scale predictions of community and ecosystem properties\nfrom simple ecological theory. Proceedings of the Royal Society B, 275:\n1375–1383. https://doi.org/10.1098/rspb.2008.0192\nPörtner HO. (2012) Integrating climate-related stressor effects on\nmarine organisms: unifying principles linking molecule to\necosystem-level changes. Marine Ecology Progress Series, 470: 273–290.\nhttps://doi.org/10.3354/meps10123\nPörtner HO, Peck MA. (2010) Climate change effects on fishes and\nfisheries: toward a cause-and-effect understanding. Journal of Fish\nBiology, 77: 1745–1779. https://doi.org/10.1111/j.1095-8649.2010.02783.x\nvan der Heide T, Roijackers RMM, van New EH, Peeters ETHM. (2006) A\nsimple equation for describing the temperature dependent growth of\nfree-floating macrophytes. Aquatic Botany, 84: 171–175. https://doi.org/10.1016/j.aquabot.2005.09.004\nWoodworth-Jefcoats PA, Blanchard JL, Drazen JC. (2019) Relative\nImpacts of Simultaneous Stressors on a Pelagic Marine Ecosystem.\nFrontiers in Marine Science, 6:383. https://doi.org/10.3389/fmars.2019.00383\n\n\n\n",
    "preview": "posts/2022-07-11-thermizer/thermizer_files/figure-html5/unnamed-chunk-8-1.png",
    "last_modified": "2024-12-18T15:34:55+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-09-07-tuning-growth-curves-with-a-shiny-gadget/",
    "title": "Tuning growth curves with a shiny gadget",
    "description": "I present to you a new shiny gadget that makes tuning a model to \nreproduce the desired growth curves feel like child's play. And\nthis is only a first glimpse of the future of interactively tuning \nmizer models.",
    "author": [
      {
        "name": "Gustav Delius",
        "url": {}
      }
    ],
    "date": "2021-09-07",
    "categories": [],
    "contents": "\n\nContents\nIntroduction\nSetting up an example\nHow difficult it was in the past\nHow easy it is now\nThe future\n\nIntroduction\nIn a previous blog post I presented a new method for tuning a mizer model to reproduce observed values for species biomasses. In the example I used there, after matching the biomasses also the growth curves had a pretty good agreement with observations. However I already warned you that that was unusual, and that you are highly unlikely to have similar luck with your own model. So in this blog post I will show you what to do if the growth curves in your model need to be adjusted.\nThis will give me an opportunity to introduce you to the mizer tuning gadget, which is an amazing interactive tool that eventually will be useful for much more than just matching growth curves.\nSetting up an example\nI will use the same species parameters and gear parameters for a North Sea model that I used in my previous blog post, but I will now also use the species interaction matrix NS_interaction that comes as an example with mizer, and which encodes that, due to only partial spatial overlap, not all species interact with each other with the same strength. With those parameters we can create the mizer model and make an initial plot of the steady state:\n\n\nparams <- newMultispeciesParams(species_params = species_params,\n                                gear_params = gear_params,\n                                interaction = NS_interaction,\n                                initial_effort = 1)\nparams <- steady(params)\nplotlySpectra(params, power = 2)\n\n\n\n\nAs discussed in that previous post, matching to the observed biomasses is easy:\n\n\nparams <- params |> calibrateBiomass() |> matchBiomasses() |> steady() |>\n    calibrateBiomass() |> matchBiomasses() |> steady() \nplotBiomassVsSpecies(params)\n\n\n\n\nThe matching did not work quite so well for Saithe, and it will become clear in a moment why that is. Let us plot the growth curves:\n\n\nplotGrowthCurves(params, species_panel = TRUE)\n\n\n\n\nIt is clear to see that the growth is too low for all species, but particularly so for Saithe.\n\n\nplotGrowthCurves(params, species = \"Saithe\")\n\n\n\n\nSaithe takes almost twice as long to reach maturity as is predicted by the von Bertalanffy growth curve. So we need to do some tuning. Before we start with that, we’ll save the current state into a new variable.\n\n\nparams_start <- params\n\n\n\nIf you want to try things for yourself, you can load this example MizerParams object with\n\n\nparams_start <- params <- readRDS(url(\"https://bit.ly/3jSNAKF\"))\n\n\n\nHow difficult it was in the past\nNow I am going to try to get the growth curve of Saithe in the model to agree with the observed growth curve, without using the new tuning gadget. I am doing that because it might be useful to understand what goes on under the hood in the tuning gadget. But I am also doing it to show off how much of an advance the tuning gadget represents. So let’s start.\nClearly we need to get Saithe to feed more rapidly. We can do that by increasing the coefficient gamma in the search volume. We don’t know how much we need to increase gamma exactly, so we try a factor of 2.\n\nIf you want to learn more about how growth is modelled in mizer, take a look at the relevant section in the mizer model description.\n\n\nspecies_params(params)[[\"Saithe\", \"gamma\"]] <- \n    2 * species_params(params)[[\"Saithe\", \"gamma\"]]\nplotGrowthCurves(params, species = \"Saithe\")\n\n\n\n\nThat helped, but is not enough. So we can try again, increasing gamma a bit further. With a little trial and error I determined that an extra factor of 1.4 would do the trick.\n\n\nspecies_params(params)[[\"Saithe\", \"gamma\"]] <- \n    1.4 * species_params(params)[[\"Saithe\", \"gamma\"]]\nplotGrowthCurves(params, species = \"Saithe\")\n\n\n\n\nUnfortunately, while we have fixed the growth curve by changing gamma, we have at the same time messed up other aspects of the model. For one thing, our initial spectra don’t represent a steady state any more. So we have to use steady() again:\n\n\nparams <- steady(params)\n\n\n\nNow this has allowed the full effect of multi-species interaction to take hold and, due to increased competition, the growth curve of Saithe is again trailling behind observations.\n\n\nplotGrowthCurves(params, species = \"Saithe\")\n\n\n\n\nBut not only that. We have also messed up the biomasses of some of the species, in particular Gurnard and Haddock, as it turns out:\n\n\nplotBiomassVsSpecies(params)\n\n\n\n\nOf course we know how to correct that:\n\n\nparams <- params |> calibrateBiomass() |> matchBiomasses() |> steady()\nplotBiomassVsSpecies(params)\n\n\n\n\nBut there is another aspects of the model that we have messed up. Let’s plot the feeding level.\n\n\nplotFeedingLevel(params)\n\n\n\n\nThe feeding level describes how satiated a fish is. The closer to 1, the more satiated the fish is and the less sensitive it therefore is to changes in prey availability. We have now made Saithe less sensitive than other species, without actually intending to do that. What we probably should have done is to change the parameter h that controls the maximum intake rate, and thus the density dependence in feeding, at the same time as gamma so as to keep the feeding level constant, at least for larvae.\nI think this is enough to explain what is involved in tuning a model to reproduce the desired growth curves and to demonstrate that it was a very tedious task in the past. We have only partially dealt with the growth curve of a single species and already are exhausted.\nHow easy it is now\nThe previous section showed us that tuning model parameters by hand is very tedious and it will take ages before we have the model in the shape we want it to be in. I’ll now discuss how to do it much faster. There are three things we need to do to make this faster solution possible:\nMake the process interactive so that we can just click around with the mouse instead of issuing long sequences of commands.\nIntelligently adjust several parameters at a time to avoid messing up other aspects of the model while we are trying to fit the growth curves.\nAutomatically recalibrate and match biomasses whenever we determine a new steady state.\nI would like you to try it out yourself, so please copy and paste the commands below to your RStudio console and run them.\nAs always we start by installing the latest version of the mizerExperimental package and loading it. The install_github() will do nothing if you already have the latest version installed. Otherwise it may prompt you to also update other packages for which there are newer versions available. You should always agree to update mizer if that is suggested.\n\n\nremotes::install_github(\"sizespectrum/mizerExperimental\")\nlibrary(mizerExperimental)\n\n\n\nNow load the un-tuned MizerParams object with\n\n\nparams_start <- readRDS(url(\"https://bit.ly/3jSNAKF\"))\n\n\n\nThe interactivity, intelligence and automation mentioned above are provided by the shiny gadget that you start with\n\n\nparams <- tuneGrowth(params_start)\n\n\n\n\nThe tool is called a “shiny gadget” not because it shines, but because it is realised with the R shiny package.\nThis will open a new tab in your browser that looks a bit like the following screenshot:\n\n\n\nThis shows two plots that are already familiar to you if you have read the previous section: the upper plot shows the growth curves and the lower plot shows the feeding levels. To the left of the plots there is a sidebar with various controls. One lets you choose which species you are currently dealing with. There is a slider to change the value of gamma. There is a button labelled “steady” that will find the steady state. So this is all very familiar.\nHowever there are also some unfamiliar buttons in the sidebar:\n“Help” opens a short tour of the user interface\n“Download” (icon) downloads the current MizerParams object\n“Return” closes the gadget and returns the current MizerParams object back to R, where with the code we used above it will then be assigned to params.\n“Undo”, “Redo” and “Rewind” (icons) allow you to go back to a previous steady state, go forward again, or rewind all the way back to your starting state.\n“previous” and “next” let you conveniently cycle through all the species.\nThere are some hidden features, that are however revealed in popups while you hover over elements. For example you can select a particular species quickly by clicking on its growth curve. You can switch to a single-species view by double-clicking on a species. Here is what you will get after double-clicking on “Saithe”:\n\n\n\nNow you know what to do: use the slider on the left to increase gamma. You can do that either by sliding or by clicking somewhere along the slider. You will notice that the graphs on the right immediately update. This makes it really easy to select the value you want.\nYou will also notice that the feeding level for the larvae remains unchanged as you change gamma. That is because the gadget automatically changes the maximum intake rate to compensate for your change in ‘gamma’.\nDon’t spend too much time tuning the growth curve for Saithe, because we know that the von Bertalanffy curve is also just an approximation to the true growth curve, and also because we know that things will change a bit again when you click the “steady” button. Instead use the “previous” button to go to fix the growth curve for Cod and so on.\nYou can also always double click on a single-species growth curve (or use the radio buttons above the plot) to go back to viewing all species at once.\nYou will have noticed that the main panel of the gadget has two tabs. The one we are currently viewing is called “Growth”. Clicking on “Biomass” gives us more familiar plots:\n\n\n\nThe upper plot is the plot comparing the model biomasses to the observed biomasses and the lower plot shows the size spectra. You don’t need to do anything on this tab. It is there just to reassure you that you have not messed up anything in your model. In particular, the model biomasses will match the observed biomasses very well. This is because behind the scenes the gadget calibrated and matched the biomasses each time you hit the “steady” button. If you don’t find that they agree well, then click the “steady” button now. There is never any harm in pressing the “steady” button.\nOnce you are happy with all your growth curves you can hit the “Return” button. Because we specified above that we wanted to assign the return value of tuneGrowth() to a variable params, you can now work further with this MizerParams object under the name params.\nThe future\nThis gadget for tuning growth curve is actually only a particular instance of a more powerful shiny gadget with many more controls and many more tabs, which allows you to adjust almost any model parameter and investigate many different aspects of you model. For example there is a tab for looking at the diets of the various species and how they change with size, a tab to look at the causes of death at various sizes, a tab to compare the size distribution of the catches in the model to observed size distributions, …\nI have been told that the full gadget, that you can start with\n\n\nparams <- tuneParams(params)\n\n\n\nis overwhelming, even though it does not yet have all the tabs and controls that I envisage. The tuneParams() function therefore allows us to just select just the bits we need for a particular task. The tuneGrowth() gadget is actually just what you get when you tell tuneParams() that you want the “growth” control and the “Growth” and “Biomass” tabs.\n\n\nparams <- tuneParams(params, controls = c(\"growth\"), \n               tabs = c(\"Growth\", \"Biomass\"))\n\n\n\nSo I think that very soon we will have a large set of targeted tools similar to tuneGrowth() to facilitate various stages of the model tuning process, but also one very powerful combined tool for those of us who like the Swiss army knife approach.\nNow, quite likely, when you try this with your own model you will run into problems. I am always eager to hear about those problems. Post about them in the comments or email them to me at gustav.delius@gmail.com.\n\n\n\n",
    "preview": "posts/2021-09-07-tuning-growth-curves-with-a-shiny-gadget/screenshot1.png",
    "last_modified": "2024-12-18T15:34:55+00:00",
    "input_file": {},
    "preview_width": 1337,
    "preview_height": 910
  },
  {
    "path": "posts/2021-08-20-a-5-step-recipe-for-tuning-the-model-steady-state/",
    "title": "A 5-step recipe for tuning the model steady state",
    "description": "Getting a steady state for your mizer model that agrees with observations\nis in principle a hard chicken and egg problem. I present the trick that\nmakes it surprisingly easy, with a 5-step recipe. I'll save tips on what\nto do when the recipe fails for later blog posts.",
    "author": [
      {
        "name": "Gustav Delius",
        "url": {}
      }
    ],
    "date": "2021-08-20",
    "categories": [],
    "contents": "\n\nContents\nWhat we want to do\nExample we will use\nWhy it is a hard problem\nThe constant reproduction trick\nSummary of the recipe\n\nWhat we want to do\nIn this blog post we will describe stage 2 of the process of building a mizer model. The stages are:\nCollect information about the important species in your ecosystem and how they are fished. This includes physiological parameters for the species as they might be found on fishbase, but also information about how abundant the species are and how they are being fished.\nCreate a mizer model that in its steady state reproduces the time-averaged observed state of your fish community. Of course your real system never is in a perfect steady state. It is continuously changing. There is much fluctuation from year to year. We will however assume that if we average observations over a number of years we obtain something that is close to the steady state. Without some such assumption it would be impossible for us to get started.\nTune the model parameters further to also reproduce time-series observations that capture some of the system’s sensitivity to perturbations, like changes in fishing pressure.\nThis blog post is only about the second stage. We will present a 5 step recipe for that stage. When the recipe works, it will only take a couple of minutes! So I hope you will try the recipe for your own model. Of course in practice there are all kinds of things that can (and will) go wrong. So I hope this blog post will lead to some exchange of experiences with the recipe.\nThe recipe is based on an important trick. I call it the constant reproduction trick. The trick is obvious once you see it, but I must admit that I struggled for a long time with mizer model building until I stumbled upon the trick.\nExample we will use\nTo make this concrete, we will consider a model for the North Sea involving 12 species. We will short-circuit stage 1 of the model-building process by basing our example on the North Sea species parameter data frame NS_species_params that comes with mizer.\nSome of the functions we will be using are still in active development in the mizerExperimental package. Therefore we will always want to make sure we are loading the latest version of the package with\n\n\nremotes::install_github(\"sizespectrum/mizerExperimental\")\nlibrary(mizerExperimental)\n\n\n\nThis blog post was compiled with mizer version 2.2.1.9006 and mizerExperimental version 2.2.1.9003\nHere is the species parameter data frame that we will be using:\n\n\nShow code\n\n# Here is how I obtained the example species_params:\nspecies_params <- NS_species_params\nspecies_params$R_max <- NULL\nspecies_params$a <- c(0.007, 0.001, 0.009, 0.002, 0.010, 0.006, 0.008, 0.004,\n                         0.007, 0.005, 0.005, 0.007)\nspecies_params$b <- c(3.014, 3.320, 2.941, 3.429, 2.986, 3.080, 3.019, 3.198,\n                         3.101, 3.160, 3.173, 3.075)\n\nyears <- getTimes(NS_sim) >= 1990 & getTimes(NS_sim) <= 2010\n# Average biomass over those 21 years\nbm_hist <- getBiomass(NS_sim)[years, ]\nspecies_params$biomass_observed <-  colSums(bm_hist) / 21\n\nlibrary(knitr)\nkable(species_params, row.names = FALSE)\n\n\nspecies\nw_inf\nw_mat\nbeta\nsigma\nk_vb\na\nb\nbiomass_observed\nSprat\n33.0\n13\n51076\n0.8\n0.681\n0.007\n3.014\n3.325300e+10\nSandeel\n36.0\n4\n398849\n1.9\n1.000\n0.001\n3.320\n1.115636e+12\nN.pout\n100.0\n23\n22\n1.5\n0.849\n0.009\n2.941\n3.047268e+11\nHerring\n334.0\n99\n280540\n3.2\n0.606\n0.002\n3.429\n4.286172e+11\nDab\n324.0\n21\n191\n1.9\n0.536\n0.010\n2.986\n1.723425e+10\nWhiting\n1192.0\n75\n22\n1.5\n0.323\n0.006\n3.080\n2.299098e+11\nSole\n866.0\n78\n381\n1.9\n0.284\n0.008\n3.019\n1.078201e+11\nGurnard\n668.0\n39\n283\n1.8\n0.266\n0.004\n3.198\n1.277013e+11\nPlaice\n2976.0\n105\n113\n1.6\n0.122\n0.007\n3.101\n2.197107e+12\nHaddock\n4316.5\n165\n558\n2.1\n0.271\n0.005\n3.160\n6.953041e+11\nCod\n39851.3\n1606\n66\n1.3\n0.216\n0.005\n3.173\n3.054369e+11\nSaithe\n39658.6\n1076\n40\n1.1\n0.175\n0.007\n3.075\n8.099535e+11\n\nFor each species we are specifying its name and some parameters characteristic of the species: its asymptotic size w_inf and maturity size w_mat, the parameters beta and sigma for its feeding kernel (we are using the default lognormal kernel for all species), the von Bertalanffy growth parameter k_vb and the parameters a and b in the allometric length-weight relationship \\(w = a l^b\\).\nIn addition, we also specify information that is specific to our ecosystem, namely the average abundance of each species, in the biomass_observed column. This is measured in grams. Because for the purpose of this blog post it is not important, we did not bother to look up real biomass estimates but instead we simply used the average over the years 1990 to 2010 in the simulated data in the NS_sim object included in the mizer package. You are invited to re-run the analysis with proper data.\nThe observed system is being fished. We need to give mizer information about how it is being fished. We do this via the gear_params data frame.\n\n\nShow code\n\n# Average fishing mortality\nf_location <- system.file(\"extdata\", \"NS_f_history.csv\", package = \"mizer\")\nf_history <- as(read.csv(f_location, row.names = 1), \"matrix\")[years, ]\nf <- colSums(f_history) / 12\n\ngear_params <- \n    data.frame(gear = \"All\",\n               species = NS_species_params$species,\n               sel_func = \"sigmoid_length\",\n               l25 =  c(7.6, 9.8, 8.7, 10.1, 11.5, 19.8, 16.4, 19.8, 11.5,\n                        19.1, 13.2, 35.3),\n               l50 = c(8.1, 11.8, 12.2, 20.8, 17.0, 29.0, 25.8, 29.0, 17.0,\n                       24.3, 22.9, 43.6),\n               catchability = f)\n\nkable(gear_params, row.names = FALSE)\n\n\ngear\nspecies\nsel_func\nl25\nl50\ncatchability\nAll\nSprat\nsigmoid_length\n7.6\n8.1\n1.3763157\nAll\nSandeel\nsigmoid_length\n9.8\n11.8\n1.3331618\nAll\nN.pout\nsigmoid_length\n8.7\n12.2\n1.3763157\nAll\nHerring\nsigmoid_length\n10.1\n20.8\n0.8626210\nAll\nDab\nsigmoid_length\n11.5\n17.0\n0.2059334\nAll\nWhiting\nsigmoid_length\n19.8\n29.0\n1.3429086\nAll\nSole\nsigmoid_length\n16.4\n25.8\n1.4424019\nAll\nGurnard\nsigmoid_length\n19.8\n29.0\n0.1342909\nAll\nPlaice\nsigmoid_length\n11.5\n17.0\n1.0296672\nAll\nHaddock\nsigmoid_length\n19.1\n24.3\n1.1690897\nAll\nCod\nsigmoid_length\n13.2\n22.9\n1.6476887\nAll\nSaithe\nsigmoid_length\n35.3\n43.6\n0.9744912\n\nWe are setting up a single gear that we call “All” which catches all species. For each species we set up the selectivity curve of the gear as a sigmoid curve with given l25 and l50 parameters. Finally we set the catchability of each species to the observed fishing mortality, averaged over the years 1990 to 2010. We will then set the fishing effort to 1, because in mizer the fishing mortality is the product of effort, catchability and selectivity.\nOur task now is to create a mizer model that describes species with the above characteristics and that has a steady state with the observed biomasses under the given fishing pressure.\nWhy it is a hard problem\nWe have a chicken and egg problem. The equilibrium abundance and size distributions of the fish are determined by their size-dependent growth and death rates. These rates in turn are determined by the abundance and size distribution of their prey and their predators. So we can’t determine the size distributions before we have determined the rates and we can’t determine the rates before we have determined the size distributions.\nBecause every species is a both prey and predator of fish of various species and sizes during their life, this is a highly coupled non-linear problem. If for example we use 100 size bins and 12 species, plus a resource spectrum, then we would have far over a thousand coupled nonlinear equations to solve simultaneously. That is not practical.\nRather than solving the equilibrium equations, another way to find a steady state is to simply evolve the time dynamics until the system settles down to a steady state. The problem with this approach is that the coexistence steady state of a size spectrum model has a very small region of attraction, so unless one starts with an initial state that is already very close to that coexistence steady state one will end up with extinctions.\nThe reason is a feedback loop: as the spawning stock biomass of a species grows, also its reproduction rate grows, leading to further growth of the spawning stock biomass and so on. Similarly as the spawning stock of another species declines, so does its reproduction rate, leading to further decline. In spite of moderating non-linear effects in the model, the general outcome is extinctions.\nWe can see the phenomenon in our North Sea example. If we simply run the dynamics, starting with the initial state set up by newMultispeciesParams(), first Sprat goes extinct, and Herring follows soon after. Just click the play button on the animation below.\n\n\nparams <- newMultispeciesParams(species_params = species_params,\n                                gear_params = gear_params,\n                                initial_effort = 1)\nsim <- project(params, t_max = 12)\nanimateSpectra(sim, power = 2)\n\n\n\n\nThe constant reproduction trick\nSo the trick is to cut the destabilising feedback loop by decoupling the reproductive rate from the spawning stock biomass. We do this by simply keeping the reproduction rate constant. The size spectrum model with constant reproduction turns out to be very stable and quickly approach a steady state, due to the smoothing effect of the feeding kernel. Once the steady state is found, we can simply adjust the reproductive efficiency of each species so that the steady state spawning stock produces the chosen reproduction rate. With that choice of the reproductive efficiency the steady state of the restricted dynamics is also the steady state of the full size spectrum model.\nHere is the code that does that. Run the animation that it produces by clicking the play button.\n\n\nparams <- newMultispeciesParams(species_params = species_params,\n                                gear_params = gear_params,\n                                initial_effort = 1)\n# Keep reproduction constant at the initial level\nparams@species_params$constant_reproduction <- getRDD(params)\nparams <- setReproduction(params, RDD = \"constantRDD\")\n# Run the dynamics with this constant reproduction\nsim <- project(params, t_max = 15)\nanimateSpectra(sim, power = 2)\n\n\n\n\nMizer has a function called steady() that does the same as the above code, namely run to steady state with constant reproduction and then adjust the reproduction parameters, and then sets the resulting steady state as the initial state of the MizerParams object.\n\n\nparams <- newMultispeciesParams(species_params = species_params,\n                                gear_params = gear_params,\n                                initial_effort = 1)\nparams <- steady(params)\nplotlySpectra(params, power = 2)\n\n\n\n\nWe now have a MizerParams object whose initial state is a steady state. Running a simulation starting with these initial conditions will show no change over time. For example the biomasses of all species will stay constant.\n\n\nsim <- project(params, t_max = 5)\nplotBiomass(sim)\n\n\n\n\nBut how do these biomasses compare to our observed biomasses?\n\n\nplotBiomassObservedVsModel(params)\n\n\n\n\nThey don’t agree at all, but that is no surprise. It would actually have been quite a coincidence if they did agree, because the newMultispeciesParams() function did not know how big our ecosystem is. It did not know that we wanted the biomasses in the entire North Sea. So initially the scale is arbitrary. The dynamics of the model are obviously independent of the scale of the system. So we have the freedom to change that scale. The calibrateBiomass() function chooses the scale so that the total biomass in the model agrees with the total observed biomass.\n\n\nparams <- calibrateBiomass(params) \nplotBiomassObservedVsModel(params)\n\n\n\n\nSo now the total biomass is correct, but for some species the biomass in the model is too high, for others it is too low.\nActually, that the size spectrum is too low for Saithe and Cod and too high for Dab and Haddock might also be suspected from the fact that they are outliers in the size-spectrum plot above. We expect in a healthy ecosystem that the total spectrum roughly follows a power law, i.e., a straight line on the log-log plot. Those species currently spoil that.\nSo we want to lower the spectra of the species whose biomass is too high in the model and raise those of the species whose biomass is too low. This is what the matchBiomasses() function does.\n\n\nparams <- matchBiomasses(params)\nplotlySpectra(params, power = 2, total = TRUE)\n\n\n\n\nIn fact, it has raised and lowered the spectra by exactly the factor needed to get the model biomasses to match the observed biomasses.\n\n\nplotBiomassObservedVsModel(params)\n\n\n\n\nOf course this is not the end of the story, because just rescaling the size spectra by constants will not again produce a steady state. All species now experience a new prey distribution and a new predator distribution, so their growth and death rates have changed. We will have to again run the dynamics to steady state.\n\n\nparams <- steady(params)\nplotBiomassObservedVsModel(params)\n\n\n\n\nThis has now spoiled the agreement between observed and model biomasses. But we can simply calibrate and match again and run to steady state again.\n\n\nparams <- params |> calibrateBiomass() |> matchBiomasses() |> steady()\nplotBiomassObservedVsModel(params)\n\n\n\n\nThe discrepancies are now quite small. We could iterate to get them even smaller:\n\n\nparams <- params |> calibrateBiomass() |> matchBiomasses() |> steady() |>\n    calibrateBiomass() |> matchBiomasses() |> steady()\nplotBiomassObservedVsModel(params)\n\n\n\n\nSo here is the picture of the steady state that matches the observed biomasses:\n\n\nplotlySpectra(params, power = 2)\n\n\n\n\nActually, even the growth rates in the steady state match the von Bertalanffy growth curves pretty well:\n\n\nplotGrowthCurves(params, species_panel = TRUE)\n\n\n\n\nBut this is a bit of a coincidence. Mizer has to choose values for the coefficient gamma of the ‘search volume’ for each species and for the coefficient ‘h’ of the maximum intake rate, both of which affect the growth rates. Because mizer has to choose them before it knows what the steady state prey distribution is for each species, it can not guarantee to choose them so as to give the correct growth rates in the steady state. You usually will have to retune them by hand. The mizerExperimental package provides a convenient shiny gadget that allows you to do that interactively, and I will talk about that in future blog posts.\nAlso remember that getting the steady state to agree with time-averaged observations is just the second stage in tuning a mizer model. Next you will want to tune the sensitivity to changes away from steady state. This will in particular involve tuning the density dependence in reproduction, among other things.\nSummary of the recipe\nWe have seen how to proceed if you have your species parameters and gear parameters and also have averaged observed biomasses for each species that you want the steady state of your model to match:\nCreate a MizerParams object from your species parameters and gear parameters with newMultispeciesParams().\nFind a coexistence steady state with steady().\nSet the scale of the model to agree with the observed total biomass with calibrateBiomass(). This does not spoil the steady state.\nUse matchBiomass() to move the size spectra of the species up or down to match the observed biomasses. This will spoil the steady state.\nGo back to step 2 to again find the steady state. Iterate steps 2, 3 and 4 as often as you like to get the steady-state biomasses to agree as precisely with your observations as you like.\nThere are several interesting ways in which the above recipe can fail. I’ll blog about them in the future. But it will be more fun if you share your attempt at following the above recipe with your species parameters and your observed biomasses. Email me at gustav.delius@gmail.com. I can then use your example to explain what to do when problems arise.\n\n\n\n",
    "preview": "posts/2021-08-20-a-5-step-recipe-for-tuning-the-model-steady-state/the-constant-reproduction-trick_files/figure-html5/unnamed-chunk-9-1.png",
    "last_modified": "2024-12-18T15:34:55+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-08-14-reproducible-research-with-mizer-and-binder/",
    "title": "Reproducible research with mizer, GitHub, RPubs and binder",
    "description": "Share your code in 5 easy steps, so that others can easily reproduce your\nresults and build on your work.",
    "author": [
      {
        "name": "Gustav Delius",
        "url": {}
      }
    ],
    "date": "2021-08-14",
    "categories": [],
    "contents": "\n\nContents\nIntroduction\nPut your code into an R notebook\nPut your notebook on GitHub\nPublish your R notebook on RPubs\nMake it executable on mybinder.org\nLet the world know\n\nIntroduction\nThere is much benefit in sharing the code that allows others to reproduce your research. Not only does it allow others to validate your results, it also allow them to build on what you have already done. This has benefits for them, but also for you because it increases engagement with your research and advances the entire field.\nThe fact that you are using mizer rather than coding everything from scratch of course makes your research code much shorter and therefore much easier for others to understand and extend.\nIn this blog post I will share my amazement at how easy it has become to share your code. There are five easy steps:\nPut your code into an R notebook and add a bit of explanation.\nMake your R notebook together with any data files publicly available in a GitHub repository.\nPublish your R notebook on RPubs so people can quickly view it, nicely rendered.\nLaunch it on mybinder.org so that people can run your code in their browser without having to install anything.\nLet the world know.\nSteps 2, 3, 4 and 5 will only take a couple of minutes each, if one knows how to, so after reading this blog post there will be no excuse not to take those steps. Obviously step 1 can take as long as you like, depending on how nicely you like your code to be documented.\nI’ll talk about each step now. As an example I’ll use code for reproducing the results and figures of (Canales, Delius, and Law 2020)\nPut your code into an R notebook\nYou probably have a jumble of R script files with the code for setting up your model and running your analysis. Now that you are done, it makes sense to organise this code a bit. A nice way of doing that is to open a new R notebook (the second entry on the “New File” menu in RStudio) and pasting your code into R chunks (you create R chunks with Ctrl-Alt-I). Then in between the R chunks you can put explanations of what the code is for. The result will look something like my example\nIn the example I modified the header to include a table of contents and to limit the height of the figures:\n---\ntitle: \"Regulation of fish stocks without ...\"\noutput: \n  html_notebook:\n    toc: true\nfig_height: 4\n---\nYou will want to load all the libraries you need in a setup chunk like\n\n\nknitr::opts_chunk$set(echo = TRUE)\nlibrary(mizer)\nlibrary(magrittr)\nlibrary(plotly)\n\n\n\nThe first line ensures that your code in the R chunks will be included when the notebook is typeset.\nThe explanatory text between the R chunks is using Markdown syntax. So for example you create section headers with #, headers of subsections with ## and so on. You can include LaTeX equations with the usual syntax. So \\(x^2\\) produces the inline expression \\(x^2\\) and \\[x^2\\] produces the displayed equation \\[x^2\\] For more information see the R Markdown Reference Guide and the R Markdown Cheat Sheet, both of which are accessible via ’Help -> Cheat Sheets` in RStudio.\nIf you have a rather large chunk of code, it may be a good idea to split it into smaller chunks, with more explanation in between. Just put your cursor at the place where you want to split the chunk and hit ‘Ctrl-Alt-I.’\nThe advice is to not be too perfectionist. Just put in enough explanations so that you yourself will still be able to remember in a year’s time what you were doing. You can always add more explanations for others later if there are requests. The point is that just by having your code out there, people will be more encouraged to engage with you if they are interested.\nPut your notebook on GitHub\nI think it is fair to say that GitHub has become the most popular place to share research code. So if you do not have an account there yet, sign up for free. Then create a new repository there for sharing your notebook.\nIf you have not used Git and GitHub before, it will really pay off in the long run for you to put in some time familiarising yourself with them and setting things up nicely. For a short introduction I recommend the chapter on Git and GitHub in the “R packages” book. Even though the book is about developing R packages, that chapter is not restricted to that use case. For a longer introduction, I recommend Happy Git and GitHub for the useR.\nBut if now you are in a hurry, you can also cheat and simply upload your R notebook and your data files using the “Add file” button on your new GitHub repository.\nPublish your R notebook on RPubs\nNow that your notebook is on GitHub, it is accessible to others, but GitHub does not display the typeset version of the notebook. For that you can use RPubs, which is a free hosting site for R notebooks.\nRStudio makes publishing on RPubs very easy: When you click on “Preview,” RStudio will open a new window with the preview of your rendered notebook, and on that window at the top right there is a “Publish” button. Click that button and then make sure to choose “RPubs” (rather than RStudio Connect). You’ll be guided through the process.\nDoing that with my example notebook leads to this. Note the “Code” button at the top right of the notebook on RPubs. It allows people to conveniently download your code.\nMake it executable on mybinder.org\nNow this step I think is amazing. It allows people to play with your code without having to install anything. Take a look at what this looks like for my example. Be a bit patient — after a few seconds you will see RStudio open in your browser. Click on “plankton-anchovy.nb.html” in the File pane and select “Open in Editor.” You will now be able to execute the code chunks as well as modify them at will. In fact, you can do anything that you can do in your local RStudio.\nScreenshotYou have to only do three things to make this magic possible:\nAdd a file to you repository called “install.R” which contains only an install.packages() command for installing all the packages that your notebook needs. See my example. You will want to include at least\n\n\ninstall.packages(c(\"mizer\", \"knitr\", \"rmarkdown\"))\n\n\n\nbut extend the list with any other packages that you load with library() in your notebook. You can create this file straight on GitHub via the “Add file” button or you can do it locally and then push to GitHub.\nAdd a file to your repository called “runtime.txt” with yesterday’s date in the format r-yyyy-mm-dd. See this example This will have the effect of setting up the environment with the current version of all packages. That means that if the packages change in the future, this will not break your notebook. The reason I recommend using yesterday’s date rather than today’s is that this feature uses the MRAN snap shots and the snapshot for today may not yet be available.\nCreate the URL for your binder. It will have the form https://mybinder.org/v2/gh/your-github-username/your-repository-name/HEAD?urlpath=rstudio where you need to replace your-github-username/your-repository-name with your GitHub user name and repository name. For my example the URL is (https://mybinder.org/v2/gh/sizespectrum/plankton-anchovy/HEAD?urlpath=rstudio).\nThe first time you visit your binder URL, mybinder will take a long time to create a Docker image. When it is done, you will see an RStudio session running in your browser, with the files from your GitHub repository available in the Files pane. When people visit the URL after you they will not have to wait so long because mybinder.org will be able to use the Docker image to start the server more quickly.\nEach time you make a change to your GitHub repository, mybinder will rebuild the Docker image the next time someone visits the URL. To save the first visitor from a long wait, you may want to visit the URL yourself each time you push a change to your GitHub repository.\nLet the world know\nYou will probably want to put the URLs to your notebook on RPubs and to your binder into the README.md file of your GitHub repository. You will want to put the link to your GitHub repository into your published paper.\nAnd then you will want to let your social networks know. If you twitter about it, include @mizer_model in your post. Also, consider writing a summary of your work for this blog.\nLast but not least, please email mizer@sizespectrum.org. We’ll include your publication in the list of publications using mizer.\n\n\n\nCanales, T. Mariella, Gustav W. Delius, and Richard Law. 2020. “Regulation of Fish Stocks Without Stock–Recruitment Relationships: The Case of Small Pelagic Fish.” Fish and Fisheries 21 (5): 857–71. https://doi.org/10.1111/faf.12465.\n\n\n\n\n",
    "preview": "posts/2021-08-14-reproducible-research-with-mizer-and-binder/rstudio.png",
    "last_modified": "2024-12-18T15:34:55+00:00",
    "input_file": {},
    "preview_width": 1277,
    "preview_height": 859
  },
  {
    "path": "posts/2021-08-08-change-model-parameters-without-using/",
    "title": "Change model parameters without using @",
    "description": "Mizer provides dedicated functions for changing model parameters. Using them\nprotects you from pitfalls arising from manipulations with the `@` symbol.",
    "author": [
      {
        "name": "Gustav Delius",
        "url": {}
      }
    ],
    "date": "2021-08-08",
    "categories": [],
    "contents": "\n\nContents\nIntroduction\nSpecies parameters\nGear parameters\nResource parameters\nRate arrays\nSummary\n\nIntroduction\nOften, after creating a mizer model, you will want to make changes to the model parameters, either to improve the model or to investigate the effect of changes. For example you might want to study the community consequence of changes in the physiology due to warmer waters, or whatever your research question is.\nMizer makes this very easy. However, it is important to use the right syntax. In particular, one should avoid the use of the @ symbol, as I will explain in this blog post. So this post serves as a reminder of how one can make changes to a model after it has been created.\nchangeAs you will know, all the parameters describing a mizer model are contained in an object of class MizerParams. You may either have created this object yourself, for example with the newMultispeciesParams() function, or received it from a colleague. Such an object has many slots holding the various pieces of information about the model.\nThere are often two ways of accessing these slots. One involves the use of the @ symbol, the other uses a dedicated mizer function. If you look at the mizer code, you will see a lot of @ symbols. However I will discuss the potential pitfalls when using the @ symbol and advocate for the use of dedicated functions that mizer provides for the purpose of changing model parameters.\nThis blog post was written with mizer version 2.2.1.9001\n\n\nlibrary(mizer)\npackageVersion(\"mizer\")\n\n\n[1] '2.2.1.9001'\n\nThroughout this post we will use the NS_params MizerParams object that comes as an example with the mizer package.\n\n\nparams <- NS_params\n\n\n\nSpecies parameters\nLet’s start with the species_params data frame. This holds species-specific parameters that are used by mizer to calculate physiological rates according to specific assumptions about the size-dependence of these rates. (The details do not concern us here, but you can find all the information on the help page of species_params(). These size-dependent rates are then stored as large arrays in the slots of the MizerParams object, to be efficiently used during model projections. But also the species parameters are stored, and can therefore be used to recalculate the rates when some species parameters change.\nYou can get the species parameters out of a MizerParams object in two ways, both giving identical results:\n\n\n# Using function\nsp <- species_params(params)\n# Using @\nspa <- params@species_params\n# These are identical\nidentical(sp, spa)\n\n\n[1] TRUE\n\nThe fact that these are identical is not surprising if you look at the code for the species_params() function:\n\n\nspecies_params\n\n\nfunction(params) {\n    params@species_params\n}\n<bytecode: 0x55ea4c495ba8>\n<environment: namespace:mizer>\n\nThe function actually only contains one statement, which accesses the species_params slot using the @ notation.\nThe difference between the two notations becomes apparent only when you want to make a change to the species parameters. Let’s assume we want to change the h parameter for the first species in our example model. It currently has the value\n\n\nspecies_params(params)$h[1]\n\n\n[1] 18.20276\n\nAs you know, this parameter h is used to calculate the maximum intake rate \\(h(w)\\) as a power-law function of size: \\(h(w) = h w^n\\). So for example the maximum intake rate at the smallest size is\n\n\ngetMaxIntakeRate(params)[1, 1]\n\n\n[1] 0.1820276\n\nNow let’s increase the value of the h parameter using the @ notation:\n\n\nparams@species_params$h[1] <- 20\n\n\n\nIf we look at the maximum intake rate, we see that it has not changed:\n\n\ngetMaxIntakeRate(params)[1, 1]\n\n\n[1] 0.1820276\n\nAll we have done is change the value in the species parameter data frame, but this did not trigger a recalculation of the maximum intake rate. We should instead have used\n\n\nspecies_params(params)$h[1] <- 20\n\n\n\nTake a look at the syntax, which is really a bit weird when compared to other programming languages. If you want to dig deeper into this, a good place to look is https://adv-r.hadley.nz/functions.html#replacement-functions.\nThis way of changing \\(h\\) does indeed change the maximum intake rate:\n\n\ngetMaxIntakeRate(params)[1, 1]\n\n\n[1] 0.2\n\nThe reason is clear if we look at the code:\n\n\n`species_params<-`\n\n\nfunction(params, value) {\n    value <- validSpeciesParams(value)\n    params@species_params <- value\n    suppressMessages(setParams(params))\n}\n<bytecode: 0x55ea4fdb2030>\n<environment: namespace:mizer>\n\nSo three things actually happen when you change a species parameter via the setter function:\nYour new value is checked for validity\nYour new value is saved in the species_params slot\nThe other slots in the MizerParams object are updated by calling setParams().\nGear parameters\nSimilar comments apply to the gear parameters. The gear parameters are used by mizer to set up the catchability and selectivity arrays. You can find more details on the help page for setting fishing. You can get the current gear parameters in two equivalent ways:\n\n\n# Using function\ngp <- gear_params(params)\n# Using @\ngpa <- params@gear_params\n# These are identical\nidentical(gp, gpa)\n\n\n[1] TRUE\n\nBut if you want to actually change the selectivity or catchability by changing the gear parameters you need to use the functional form. Here is the current gear_params data frame in the example model:\n\n\ngear_params(params)\n\n\n         gear species   sel_func knife_edge_size catchability\n1  Industrial   Sprat knife_edge              13            1\n2  Industrial Sandeel knife_edge               4            1\n3  Industrial  N.pout knife_edge              23            1\n4     Pelagic Herring knife_edge              99            1\n5        Beam     Dab knife_edge              21            1\n6       Otter Whiting knife_edge              75            1\n7        Beam    Sole knife_edge              78            1\n8       Otter Gurnard knife_edge              39            1\n9        Beam  Plaice knife_edge             105            1\n10      Otter Haddock knife_edge             165            1\n11      Otter     Cod knife_edge            1606            1\n12      Otter  Saithe knife_edge            1076            1\n\nIf, for example, we want to reduce the catchability of Sprat with the Industrial gear to 0.8 we would do\n\n\ngear_params(params)$catchability[1] <- 0.8\n\n\n\nNote that changing gear parameters in the species_params data frame will not have the desired effect. You need to change them in the gear_params data frame.\nResource parameters\nNot surprisingly, the same applies to the resource parameters. These are used to set up the size-dependent carrying capacity and replenishment rate for the resource. You should access them with\n\n\nresource_params(params)\n\n\n$kappa\n[1] 1e+11\n\n$lambda\n[1] 2.133333\n\n$r_pp\n[1] 10\n\n$n\n[1] 0.6666667\n\n$w_pp_cutoff\n[1] 9.820907\n\nand change them with, for example,\n\n\nresource_params(params)$r_pp <- 4\n\n\n\nRate arrays\nWhen you call newMultispeciesParams(), then mizer uses the information in species_params, gear_params and resource_params to set up various arrays that will later make it much faster to run simulations of the model. If you are not happy with how mizer fills these arrays, you can also change them directly. And again you can do that either with @ notation or without.\nLet’s take the example of the maximum intake rate \\(h(w)\\) that we already discussed earlier. This is stored in the intake_max slot of the MizerParams object, as a two-dimensional array, with one row for each species and one column for each size bin. You can get at this way in the two equivalent ways:\n\n\nidentical(getMaxIntakeRate(params), params@intake_max)\n\n\n[1] TRUE\n\nYou may wonder, why the function is called getMaxIntakeRate() rather than intake_max(), and I am wondering too. Naming things is difficult, and I now think that I made a bad choice when choosing those names. It gets worse when we now look at the syntax for changing intake_max.\nWe can either do it with the @ notation, for example\n\n\nparams@intake_max <- 2 * params@intake_max\n\n\n\nor we can do it without @ notation\n\n\nparams <- setMaxIntakeRate(params, intake_max = 2 * getMaxIntakeRate(params))\n\n\n\nThis is ugly, and in future versions of mizer I think we will also allow\n\n\nintake_max(params) <- 2 * intake_max(params)\n\n\n\nBut for now we are stuck with the functions that are all listed on the [help page] for setParams(). Note that these functions do not modify the params object in place, but create a new MizerParams object, which we then have to assign to a variable.\nAgain there are benefits in avoiding directly accessing the slot with @. These are:\nThe new value you assign is checked for validity. If you make a mistake in an assignment using @ you will not get any warning and instead will run into mysterious and cryptic error messages later.\nThe new value gets protected from automatically being overwritten when you make changes to other parameters.\nWe illustrate the second point with a simple example. Let’s set one entry in the metab slot, which holds the size-dependent metabolic rates, to a particular value.\n\n\nparams@metab[1, 1] <- 2\nparams@metab[1, 1]\n\n\n[1] 2\n\nLet us then make a totally unrelated change, say by changing the reproductive efficiency of the 5th species and look again at our entry in metab.\n\n\nspecies_params(params)$erepro[5] <- 0.1\nparams@metab[1, 1]\n\n\n[1] 0.02891793\n\nThe reason for this is that the change in the species parameter has triggered a recalculation of the rate arrays from the species parameters, overwriting our manual change.\nNow let’s try the same with the proper way of changing the metabolic rate.\n\n\nmetab <- getMetabolicRate(params)\nmetab[1, 1] <- 2\nparams <- setMetabolicRate(params, metab = metab)\n\n\n\nNow this will not get overwritten when some other parameter changes.\n\n\nspecies_params(params)$erepro[5] <- 0.1\nparams@metab[1, 1]\n\n\n[1] 2\n\nThe way that was done internally is by attaching a comment to the metab slot.\n\n\ncomment(params@metab)\n\n\n[1] \"set manually\"\n\nYou could have chosen a more informative comment, for example\n\n\ncomment <- \"Just changed the [1, 1] entry for test purposes.\"\nparams <- setMetabolicRate(params, metab = metab,\n                           comment_metab = comment)\n\n\n\nAll that matters is that there is a comment. This also tells us how we can un-protect a slot so that it can be auto-computed from the species parameters again:\n\n\ncomment(params@metab) <- NULL\n\n\n\n\n\nspecies_params(params)$erepro[5] <- 0.1\nparams@metab[1, 1]\n\n\n[1] 0.02891793\n\nSummary\nWe have seen how to change species parameters, gear parameters, resource parameters or other slots in a MizerParams object by using the appropriate functions. You can find a complete list of these functions in the mizer reference pages. We discussed how this avoids the pitfalls that arise when accessing slots directly with the @ notation. I hope this will be useful to you when you explore your own mizer model.\nThis blog post was motivated by a question by Leslie Garay-Narváez. Please keep the questions coming.\n\n\n\n",
    "preview": "posts/2021-08-08-change-model-parameters-without-using/change.jpg",
    "last_modified": "2024-12-18T15:34:55+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-08-03-density-dependence-in-reproduction/",
    "title": "Density-dependence in reproduction",
    "description": "The take-home message is that it is important to set the density\ndependence in your model appropriately and that with the help of the\n`setBevertonHolt()` function you can easily make changes to the density\ndependence without spoiling other aspects of your calibrated model.",
    "author": [
      {
        "name": "Gustav Delius",
        "url": {}
      }
    ],
    "date": "2021-08-03",
    "categories": [],
    "contents": "\n\nContents\nStock-recruitment relationship\nAn example model\nBeverton-Holt curves\nThe reproduction level\nChanging the reproduction level\nSensitivity to fishing\nMore about setBevertonHolt()\nTurning off density dependence\nSummary\n\nIn this blog post I want to discuss the purpose of the setBevertonHolt() function, which was improved in the latest version 2.2.1 of mizer to make it convenient to control the density-dependence in reproduction. We’ll introduce the new concept of the reproduction level and meet the related new function getReproductionLevel().\nBefore we get started we need to clarify what we mean by density dependence in reproduction in a mizer model.\nStock-recruitment relationship\nUsually, in a fisheries model, density dependence is specified via a stock-recruitment relationship, which gives a non-linear relationship between the spawning stock biomass and the recruitment. This relationship could, for example, be described by a Beverton-Holt curve. In that case for low spawning stock biomass the recruitment is assumed to be linearly proportional to the spawning stock biomass but for higher spawning stock biomass the curve flattens and asymptotically approaches a maximum recruitment rate that will never be exceeded, no matter how high the spawning stock biomass.\nIn a mizer model things are different because many of the causes of the density dependence in recruitment are explicitly modelled mechanistically, so don’t need to be imposed externally. These causes are:\nThe rate at which a spawner invests energy into reproduction depends on its food intake. So if there is a high abundance of fish and hence a lot of competition for prey, each spawner will produce fewer offspring.\nFish larvae are exposed to mortality from predation by larger fish. So the higher the abundance of larger fish, the higher the mortality and the fewer of the offspring will reach recruitment size.\nThe rate at which fish larvae grow, and hence the time they take to reach recruitment size, will depend on the availability of resources. If there are many fish larvae competing for limited resources, they will be exposed to mortality for longer, meaning fewer of them will reach recruitment size.\nAll these causes of density dependence are automatically taken into account in mizer, because growth depends on the abundance of prey and mortality depends on the abundance of predators. This dynamically generates fully multi-species stock-recruitment relationships.\nHowever, there are other causes of density dependence besides the three listed above, and these are not explicitly modelled mechanistically by mizer. An example would be the limited carrying capacity of suitable spawning grounds and other spatial effects. The way such additional density dependencies can be taken into account in a mizer model is by specifying a non-linear relationship between the energy that the spawners invest into reproduction and the number of larvae this results in. It is this extra density-dependence that we will be concerned with in this blog post.\nAn example model\nTo make things concrete in this blog post we will use the example MizerParams object NS_params, included in mizer, that describes the fish community in the North Sea. Let’s have a quick look at that MizerParams object.\nFirst we load the mizer package. We are using the currently latest version of mizer, version 2.2.1.\n\n\nlibrary(mizer)\npackageVersion(\"mizer\")\n\n\n[1] '2.2.1'\n\nA MizerParams object comes with initial size spectra for all species and the resource. Let’s plot these for the North Sea params object.\n\n\nparams <- NS_params\nplotSpectra(params, power = 2)\n\n\n\n\nThese initial spectra were chosen to describe a steady state of the model, meaning that if we project forward in time with constant fishing effort, the abundances stay constant. Let’s verify that.\n\n\nsim <- project(NS_params, t_max = 20)\nplotBiomass(sim)\n\n\n\n\nWe’ll use this model below\nBeverton-Holt curves\nBy default, mizer uses a Beverton-Holt curve to describe the relationship between the rate \\(E_R\\) at which energy is invested into reproduction and the rate \\(R\\) at which offspring are produced.\nTo make this concrete, we’ll look at an example. I have written a function for the purpose of this blog post called plotBevertonHolt() which we can use to look at the Beverton-Holt curve for a given species in a model.\n\n\nShow code\n\nlibrary(ggplot2)\nplotBevertonHolt <- function(params, species) {\n  select <- species_params(params)$species == species\n  erepro <- species_params(params)$erepro[select]\n  w0 <- params@w[params@w_min_idx[select]]\n  E_R_ss <- getRDI(params)[select] / erepro * 2 * w0\n  R_dd_ss <- getRDD(params)[select]\n  R_max  <- species_params(params)$R_max[select]\n  E_R <- seq(0, 2 * E_R_ss, length.out = 50)\n  R_di = erepro * E_R / 2 / w0\n  R_dd <- R_di / (1 + R_di / R_max)\n  df <- melt(data.frame(E_R, R_dd, R_di, R_max), id.vars = \"E_R\")\n  ggplot(df) +\n    geom_line(aes(x = E_R, y = value, linetype = variable)) +\n    geom_point(aes(x = E_R_ss, y = R_dd_ss), size = 3, color = \"red\") +\n    ylim(NA, 1.1 * R_max) +\n    ylab(\"Reproduction rate [eggs/year]\") +\n    xlab(\"Energy invested [g/year]\")\n}\n\n\n\nWe use that function to plot the Beverton-Holt curve for Gurnard in our example model\n\n\nplotBevertonHolt(params, \"Gurnard\")\n\n\n\n\nThe solid line is the Beverton-Holt curve. The horizontal dashed line shows the maximum reproduction rate that the Beverton-Holt curve approaches for large \\(E_R\\) and the dotted line shows the density-independent reproduction. The current reproduction rate is marked on the curve by a red dot. The curve shows us how the reproduction rate would change as the rate of investment into reproduction changes.\nThere are two parameters involved in determining this curve:\nThe reproductive efficiency erepro determines the slope of the curve when reproduction is low,\nThe maximum reproduction rate R_max determines the asymptote to which the curve levels off eventually.\nLet us look up the values to which the reproductive efficiency erepro and the maximal recruitment rate R_max are set for Gurnard in this example model.\n\n\nselect_gurnard <- species_params(params)$species == \"Gurnard\"\nspecies_params(params)[select_gurnard, c(\"erepro\", \"R_max\")]\n\n\n        erepro    R_max\nGurnard      1 1.65e+12\n\nThe reproduction level\nWe define the reproduction level as the ratio between the current reproduction rate and the maximum reproduction rate. Thus it is a number between 0 and 1. It is similar to the feeding level which in mizer is defined as the ratio between tha actual feeding rate and the maximum feeding rate.\nSince version 2.2.1 of mizer there is a function getReproductionLevel() for calculating the reproduction level.\n\n\nreproduction_level <- getReproductionLevel(params)\nreproduction_level\n\n\n     Sprat    Sandeel     N.pout    Herring        Dab    Whiting \n0.99074238 0.99987053 0.92829319 0.99198802 0.99578514 0.98718674 \n      Sole    Gurnard     Plaice    Haddock        Cod     Saithe \n0.99643774 0.44189813 0.08022106 0.94443443 0.99993658 0.99767830 \n\nWe see that the reproduction level of Gurnard is 0.4418981, which agrees with the height of the red dot in relation to the maximum in the above plot of the Beverton Holt curve for Gurnard.\nMost of the other species have unrealistically large reproduction levels, very close to 1. To see why that is bad let’s look for example at the curve for Cod:\n\n\nplotBevertonHolt(params, \"Cod\")\n\n\n\n\nThis looks so strange because the actual reproduction rate is very close to the maximum reproduction rate, so that we are very far to the right of the Beverton-Holt curve where it is almost flat. The density dependence here is so strong that an increase or decrease in the energy invested into reproduction leads to almost no change in the reproduction. In other words, the spawning stock biomass has almost no effect on the number of eggs produced. That is not realistic, so before using this model we should reduce the reproduction level.\nChanging the reproduction level\nWe could reduce the reproduction level by either reducing the reproductive efficiency erepro or by increasing R_max, but there is a subtlety. Given that the reproduction level is the ratio of the actual reproduction rate and the maximum reproduction rate R_max, we might think that doubling R_max would reduce the reproduction level by a factor of 2. Let’s check that in the example of Cod:\n\n\nselect_cod <- species_params(params)$species == \"Cod\"\nparams_changed_R_max <- params\nspecies_params(params_changed_R_max)$R_max[select_cod] <- \n    2 * species_params(params_changed_R_max)$R_max[select_cod]\ngetReproductionLevel(params_changed_R_max)[select_cod]\n\n\n      Cod \n0.9998732 \n\nThe reproduction level has changed very little. The reason is that besides raising the maximum reproduction, we have also changed the Beverton-Holt curve and the actual reproduction has also increased.\nThe other problem with changing either erepro or R_max in isolation is that we will move away from the steady state. We can see that by projecting our changed params object forward in time:\n\n\nsim_changed_R_max <- project(params_changed_R_max, t_max = 20)\nplotBiomass(sim_changed_R_max, species = \"Cod\")\n\n\n\n\nThis is bad news if we had carefully calibrated our model to observed biomasses for example.\nWhat we need to do is change both erepro and R_max at the same time in such a way that the actual reproduction does not change. This is what the function setBevertonHolt() does.\n\n\nparams2 <- setBevertonHolt(params, reproduction_level = c(Cod = 0.5))\nplotBevertonHolt(params2, \"Cod\")\n\n\n\n\nTo see more clearly what has happened, we extend our plotBevertonHolt() function to show both the old and the new Beverton-Holt curve in the same graph.\n\n\nShow code\n\nplotBevertonHolt2 <- function(params, params2, species) {\n  select <- species_params(params)$species == species\n  erepro <- species_params(params)$erepro[select]\n  w0 <- params@w[params@w_min_idx[select]]\n  E_R_ss <- getRDI(params)[select] / erepro * 2 * w0\n  R_dd_ss <- getRDD(params)[select]\n  E_R <- seq(0, 2 * E_R_ss, length.out = 50)\n  \n  R_max  <- species_params(params)$R_max[select]\n  R_di = erepro * E_R / 2 / w0\n  R_dd <- R_di / (1 + R_di / R_max)\n  df <- melt(data.frame(E_R, R_dd, R_di, R_max), id.vars = \"E_R\")\n  df$Model <- \"Model 1\"\n  \n  erepro <- species_params(params2)$erepro[select]\n  R_max  <- species_params(params2)$R_max[select]\n  R_di = erepro * E_R / 2 / w0\n  R_dd <- R_di / (1 + R_di / R_max)\n  df2 <- melt(data.frame(E_R, R_dd, R_di, R_max), id.vars = \"E_R\")\n  df2$Model <- \"Model 2\"\n  \n  ggplot(rbind(df, df2)) +\n    geom_line(aes(x = E_R, y = value, linetype = variable,\n                  colour = Model, size = Model)) +\n    geom_point(aes(x = E_R_ss, y = R_dd_ss), size = 3, color = \"red\") +\n    ylim(NA, 1.1 * R_max) +\n    ylab(\"Reproduction rate [eggs/year]\") +\n    xlab(\"Energy invested [g/year]\") +\n    labs(linetype = \"\", size = \"R_max\", colour = \"R_max\") +\n    scale_size_manual(values = c(0.5, 1)) +\n    scale_colour_manual(values = c(\"blue\", \"black\")) +\n    scale_linetype_manual(values = c(\"solid\", \"dashed\", \"dotted\"))\n}\n\n\n\n\n\nplotBevertonHolt2(params, params2, \"Cod\")\n\n\n\n\nThis shows that the red dot that marks the steady state value lies on both the old (blue) and the new (black) curve. This was achieved by lowering erepro at the same time as increasing R_max. The old values were\n\n\nspecies_params(params)[select_cod, c(\"erepro\", \"R_max\")]\n\n\n    erepro    R_max\nCod      1 8.26e+09\n\nand the new values are\n\n\nspecies_params(params2)[select_cod, c(\"erepro\", \"R_max\")]\n\n\n          erepro       R_max\nCod 0.0001270809 16549691091\n\nSo the change in the reproduction level has been achieved without a change to the steady state. We can verify this:\n\n\nsim2 <- project(params2, t_max = 20)\nplotBiomass(sim2)\n\n\n\n\nSensitivity to fishing\nThe reason why it matters what level of density dependence in reproduction is chosen for the model is that it affects the sensitivity of the model to perturbations, for example to changes in fishing pressure. To illustrate this we will plot the sustainable fishing yield as a function of fishing mortality.\nThe mizerExperimental package contains a function plotYieldVsF() that creates such a Yield versus F plot. The mizerExperimental package is updated frequently and thus it is a good idea to install the latest version\n\n\nremotes::install_github(\"sizespectrum/mizerExperimental\")\n\n\n\n\n\nlibrary(mizerExperimental)\npackageVersion(\"mizerExperimental\")\n\n\n[1] '2.2.1.9000'\n\nHere is the Yield versus F plot for Cod in the old model with the high reproduction level:\n\n\nplotYieldVsF(params, \"Cod\")\n\n\n\n\nThis plot shows the sustainable fishing yields at different levels of imposed fishing mortality. This is calculated by running the model with each level of fishing mortalit for long enough to reach a steady state. Then the yield in that steady state is plotted. For high fishing mortality the stock should collapse and the yield in the steady state should therefore be very low at high fishing mortalities. However in this model we see that the stock can sustain unrealistically high fishing mortalities without collapsing.\nFor the new model, with a reproduction level of 1/2, the curve looks more realistic:\n\n\nplotYieldVsF(params2, \"Cod\")\n\n\n\n\nIn this model at a fishing mortality of 2 per year the stock collapses completely, leading to zero yield.\nMore about setBevertonHolt()\nAs you can see from the help page of setBevertonHolt(), you can adjust the density dependence in the reproduction of several species at once. For example we can try to set the reproduction level to 1/2 for all species:\n\n\nparams3 <- setBevertonHolt(params, reproduction_level = 0.5)\n\n\nWarning in setBevertonHolt(params, reproduction_level = 0.5): The\nfollowing species require an unrealistic reproductive efficiency\ngreater than 1: Gurnard, Plaice\n\nThis gave us a warning. Let’s take a look at plaice, for example:\n\n\nselect_plaice <- species_params(params)$species == \"Plaice\"\nspecies_params(params3)[select_plaice, c(\"erepro\", \"R_max\")]\n\n\n         erepro        R_max\nPlaice 1.842465 6.556383e+13\n\nWe see that to achieve a reproduction level of 1/2 while maintaining plaice at its initial abundance, it would need a very high reproductive efficiency.\nLet’s see what happens if we try to force the reproductive efficiency to a more realistic level of 0.1:\n\n\nparams3 <- setBevertonHolt(params, erepro = c(\"Plaice\" = 0.1))\n\n\nWarning in setBevertonHolt(params, erepro = c(Plaice = 0.1)): For the\nfollowing species the requested `erepro` was too small and has been\nincreased to the smallest possible value: Plaice\n\n\n\nspecies_params(params3)[select_plaice, c(\"erepro\", \"R_max\")]\n\n\n          erepro R_max\nPlaice 0.9212325   Inf\n\nTo understand what is going on here we have to recall that setBevertonHolt() will not make changes that would change the abundances in the model. The level of abundance for plaice specified in the model can only be achieved with a high reproductive efficiency.\nIf we want to force the change in erepro we can do that but have to accept that the steady state will change:\n\n\nspecies_params(params3)$erepro[select_plaice] <- 0.1\nsim3 <- project(params3, t_max = 20)\nplotlyBiomass(sim3)\n\n\n\n\nWe see that this change also affects the abundances of the other species. I think this nicely illustrates the differences of adjusting reproduction parameters with setBevertonHolt() as opposed to changing them directly.\nTurning off density dependence\nWe can also set the reproduction level to 0.\n\n\nparams4 <- setBevertonHolt(params, reproduction_level = 0)\n\n\n\nThis does not mean that we have set reproduction to 0, but rather that we have turned off the density dependence in reproduction. In other words, the reproduction level is zero because we have set the maximum reproduction rate to infinity.\n\n\nspecies_params(params4)$R_max\n\n\n [1] Inf Inf Inf Inf Inf Inf Inf Inf Inf Inf Inf Inf\n\nI want to stress that the fact that we have turned off all the density dependence in reproduction does not mean that the stock-recruitment relationship is linear. All the density dependencies mentioned at the start of this blog post are still operating. We are simply not imposing any additional density dependence that is not already captured by the model.\nThe built-in density dependencies are enough to keep the model stable, in the sense that if we make changes to the initial abundances, after a time the system will settle down to a steady state again:\n\n\nparams5 <- params4\ninitialN(params5) <- 4 * initialN(params4)\nsim5 <- project(params5)\nplotlyBiomass(sim5)\n\n\n\n\nSummary\nWe have discussed that in the mizer model many sources of density dependence in recruitment are captured automatically but that one can take into account additional density dependence in recruitment by imposing a density dependence on the reproduction, by which we mean to impose a non-linear relation between the rate at which energy is invested into reproduction and the rate at which offspring are produced.\nWe looked at some Beverton-Holt curves which are used in mizer by default to encode this non-linearity. These curves are specified by two parameters: the reproductive efficiency erepro and the maximum reproduction rate R_max. The setBevertonHolt() function allows us to change both of these parameters together without changing the current reproduction rate. It only affects the behaviour of the model when it is perturbed away from the current state.\nTherefore the setBevertonHolt() function allows us to control the sensitivity of the model to perturbations, like changes in fishing for example, without changing the steady-state properties. This allows a two-stage approach to calibrating a mizer model: in a first step one calibrates the steady state properties to reproduce averaged observations, like growth rates and biomasses or yields of species for example. In a second step on the calibrates the sensitivity of the model, for example by matching it to time series observations.\n\n\n\n",
    "preview": "posts/2021-08-03-density-dependence-in-reproduction/density-dependence-in-reproduction_files/figure-html5/unnamed-chunk-13-1.png",
    "last_modified": "2024-12-18T15:34:55+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to the mizer blog",
    "description": "mizer is now 9 years old. mizer is becoming more social. Time to start a blog.",
    "author": [
      {
        "name": "Gustav Delius",
        "url": {}
      }
    ],
    "date": "2021-08-01",
    "categories": [],
    "contents": "\nThere is now a sizeable and diverse community of mizer users. This blog, I hope, will help keep us informed of what we are all up to and to share our experiences and our best practices.\nI will use this blog from time to time to explain new or less well known features of mizer. But I would like to encourage you to contribute to this blog too. Introduce us to your model or to your research. Or discuss ways in which you have extended mizer or would like to extend mizer. Or show us new ways of using mizer. All you need to do is create an R Markdown document containing your text and your code and either email it to me at mizer@sizespectrum.org or, if you are more of a GitHub wizard, create a pull request directly to the repository at (https://github.com/sizespectrum/mizerBlog).\nThis blog is using distill for R Markdown, which gives it some nice features. The one that I like the most is that any code blocks that you include in your post will automatically be highlighted and linked to documentation pages. For example if your R Markdown document contains a code block with\n\nlibrary(mizer)\nplotlySpectra(NS_params)\n\nthen what will be displayed on the blog is\n\n\nlibrary(mizer)\nplotlySpectra(NS_params)\n\n\n\n\nNote how the function names and package names have become links. Click on them to see what they do. If you are using packages or functions that your readers are not familiar with yet, this autolinking allows them to look them up very conveniently.\nUnfortunately code highlighting and autolinking currently does not work for inline code. This is due to a known bug in distill and will hopefully be fixed soon.\nThe output of the plotlySpectra() function is an interactive plot and this got embedded into the blog automatically. Play around with it a bit. It behaves just as it would if you viewed it in your RStudio viewer.\nAs the blog grows, we can start using categories to organise the posts. The distill framework provides all such standard blog features. One feature I have enabled already are comments, using the Disqus service.\n\n\n\n",
    "preview": {},
    "last_modified": "2024-12-18T15:34:56+00:00",
    "input_file": {}
  }
]
